<!DOCTYPE html>
<html lang="en">
<head>
    <meta charset="UTF-8">
    <meta name="viewport" content="width=device-width, initial-scale=1.0">
    <meta name="description" content="Personal website and blog of Vatsal Ambastha" id="meta-description">
    <meta name="keywords" content="Unity, game development, virtual reality, ManageXR, open source, unity3d, AR, VR" id="meta-keywords">
    <link rel="canonical" href="https://adrenak.github.io?page=home" id="canonical-link">
    <title id="page-title">Vatsal Ambastha</title>
    <!-- Favicon -->
    <link rel="icon" type="image/x-icon" href="favicon.ico" id="favicon-link">
    <link rel="apple-touch-icon" href="apple-touch-icon.png" id="apple-touch-icon-link">
    <link rel="stylesheet" href="https://fonts.googleapis.com/css2?family=JetBrains+Mono:wght@400;500;600&display=swap">
    <link rel="stylesheet" href="styles/base.css">
    <link rel="stylesheet" href="styles/theme.css">
    <link rel="stylesheet" href="styles/layout.css">
    <link rel="stylesheet" href="styles/navigation.css">
    <link rel="stylesheet" href="styles/mobile.css">
    <link rel="stylesheet" href="styles/content.css">
    <link rel="stylesheet" href="styles/responsive.css">
    <!-- Prism.js for syntax highlighting -->
    <link href="https://cdnjs.cloudflare.com/ajax/libs/prism/1.29.0/themes/prism.min.css" rel="stylesheet" />
    <script src="https://cdnjs.cloudflare.com/ajax/libs/prism/1.29.0/components/prism-core.min.js"></script>
    <script src="https://cdnjs.cloudflare.com/ajax/libs/prism/1.29.0/plugins/autoloader/prism-autoloader.min.js"></script>
</head>
<body>
    <div class="container">
        <!-- Hamburger Menu Button (mobile/portrait only) -->
        <button class="hamburger-menu" id="hamburger-menu" aria-label="Toggle menu">
            <span></span>
            <span></span>
            <span></span>
        </button>
        
        <!-- Left Sidebar -->
        <aside class="sidebar" id="sidebar">
            <div class="sidebar-header">
                <h1>Vatsal Ambastha</h1>
            </div>
            <nav class="sidebar-main-nav">
                <a href="#" class="nav-link active" data-url="?page=home">
    <span class="nav-icon">üè†</span>
    <span>Home</span>
</a>
<a href="#" class="nav-link" data-url="?page=posts">
    <span class="nav-icon">‚úçÔ∏è</span>
    <span>Posts</span>
</a>

            </nav>
            <nav class="sidebar-nav">
                <div class="sidebar-section">
    <h3 class="section-title"></h3>
    <ul class="section-list">
        <li>
            <a href="#" class="nav-link" data-url="?page=work">
                <span>Work</span>
            </a>
        </li>
    </ul>
</div>
<div class="sidebar-section">
    <h3 class="section-title">üîó Links</h3>
    <ul class="section-list">
        <li>
            <a href="mailto:ambastha.vatsal@gmail.com" class="nav-link" target="_blank" rel="noopener noreferrer">
                <span>Email</span>
                <span class="external-icon">‚Üó</span>
            </a>
        </li>
        <li>
            <a href="https://www.github.com/adrenak" class="nav-link" target="_blank" rel="noopener noreferrer">
                <span>Github</span>
                <span class="external-icon">‚Üó</span>
            </a>
        </li>
        <li>
            <a href="https://www.linkedin.com/in/vatsalambastha" class="nav-link" target="_blank" rel="noopener noreferrer">
                <span>LinkedIn</span>
                <span class="external-icon">‚Üó</span>
            </a>
        </li>
    </ul>
</div>

            </nav>
            <div class="sidebar-footer">
    <a href="https://adrenak.github.io" class="footer-link" target="_blank" rel="noopener noreferrer">2025 ¬© Vatsal Ambastha</a>
    <a href="https://github.com/adrenak/gorky" class="footer-link" target="_blank" rel="noopener noreferrer">Get this website template</a>
</div>

        </aside>
        
        <!-- Overlay for mobile (closes sidebar when clicked) -->
        <div class="sidebar-overlay" id="sidebar-overlay"></div>

        <!-- Main Content -->
        <main class="main-content">
            <div id="markdown-content">
                <div id="content-content/customization-md" class="content-section" data-title="Customization" data-description="Learn how to customize fonts, colors, and styling to make your website unique" data-keywords="customization, styling, fonts, colors, CSS, theme" style="display: none;">
<h1>Customization Guide</h1>
<p>This guide will help you customize the look and feel of your Gorky website. <strong>Most customization is done through <code>styles/theme.css</code></strong> - this is where you&#39;ll find all the important theme-related properties like colors, fonts, and spacing.</p>
<h2>The Most Important File: <code>theme.css</code></h2>
<p><strong><code>styles/theme.css</code> is where most customization happens.</strong> This file contains all theme-related CSS properties organized for easy customization:</p>
<ul>
<li><strong>Fonts</strong> (body, code)</li>
<li><strong>Sidebar</strong> background and text colors (idle, hovered, selected states)</li>
<li><strong>Content</strong> background color, text color, link colors</li>
<li><strong>Content</strong> line spacing</li>
<li><strong>Blockquote</strong> colors and borders</li>
</ul>
<p>Simply edit <code>styles/theme.css</code> to change your site&#39;s appearance. Most users won&#39;t need to touch the other CSS files.</p>
<h2>CSS File Structure</h2>
<p>While <code>theme.css</code> handles most customization, the styles are organized into several files:</p>
<ul>
<li><strong><code>styles/theme.css</code></strong> ‚≠ê - <strong>Most important!</strong> Contains fonts, colors, and theme properties</li>
<li><strong><code>styles/base.css</code></strong> - CSS reset and container layout (rarely needs editing)</li>
<li><strong><code>styles/layout.css</code></strong> - Layout structure, padding, margins (structural properties)</li>
<li><strong><code>styles/navigation.css</code></strong> - Navigation structure and layout (not colors)</li>
<li><strong><code>styles/content.css</code></strong> - Content structure, spacing, typography structure</li>
<li><strong><code>styles/mobile.css</code></strong> - Mobile-specific styles</li>
<li><strong><code>styles/responsive.css</code></strong> - Responsive breakpoints and adjustments</li>
</ul>
<h2>Customizing Fonts</h2>
<h3>Main Body Font</h3>
<p>The main font for all content is set in <code>styles/theme.css</code>:</p>
<pre><code class="language-css">body {
    font-family: -apple-system, BlinkMacSystemFont, &#39;Segoe UI&#39;, Roboto, Oxygen, Ubuntu, Cantarell, sans-serif;
}
</code></pre>
<p><strong>To change it</strong>, edit <code>styles/theme.css</code> and replace with your preferred font:</p>
<pre><code class="language-css">body {
    font-family: &#39;Your Font Name&#39;, sans-serif;
}
</code></pre>
<p><strong>Using Google Fonts:</strong></p>
<ol>
<li><p>Add the font link in <code>index-template.html</code> (in the <code>&lt;head&gt;</code> section):</p>
<pre><code class="language-html">&lt;link href=&quot;https://fonts.googleapis.com/css2?family=Inter:wght@400;600&amp;display=swap&quot; rel=&quot;stylesheet&quot;&gt;
</code></pre>
</li>
<li><p>Update <code>styles/theme.css</code>:</p>
<pre><code class="language-css">body {
    font-family: &#39;Inter&#39;, sans-serif;
}
</code></pre>
</li>
</ol>
<p><strong>Popular font choices:</strong></p>
<ul>
<li><code>&#39;Inter&#39;, sans-serif</code> - Modern, clean sans-serif</li>
<li><code>&#39;Merriweather&#39;, serif</code> - Readable serif font</li>
<li><code>&#39;Playfair Display&#39;, serif</code> - Elegant serif</li>
</ul>
<h3>Code Font</h3>
<p>Code blocks and inline code use a monospace font. Edit <code>styles/theme.css</code>:</p>
<pre><code class="language-css">#markdown-content code,
#markdown-content pre {
    font-family: &#39;JetBrains Mono&#39;, &#39;Courier New&#39;, monospace;
}
</code></pre>
<p><strong>Popular monospace fonts:</strong></p>
<ul>
<li><code>&#39;JetBrains Mono&#39;</code> - Modern monospace (already included via Google Fonts)</li>
<li><code>&#39;Fira Code&#39;</code> - Programming font with ligatures</li>
<li><code>&#39;Source Code Pro&#39;</code> - Clean code font</li>
</ul>
<h2>Customizing Colors</h2>
<p>All color customization happens in <code>styles/theme.css</code>. This is much simpler than before!</p>
<h3>Sidebar Colors</h3>
<p><strong>Sidebar background:</strong></p>
<pre><code class="language-css">.sidebar {
    background-color: #f5f5f5;
}
</code></pre>
<p><strong>Sidebar text colors (idle state):</strong></p>
<pre><code class="language-css">.sidebar-header h1 {
    color: rgb(0, 0, 0);
}

.nav-link {
    color: rgba(0, 0, 0, 0.6);
}

.section-title {
    color: rgba(0, 0, 0, 0.75);
}
</code></pre>
<p><strong>Sidebar text colors (hovered state):</strong></p>
<pre><code class="language-css">.nav-link:hover {
    background-color: rgb(188, 188, 188);
    color: rgba(0, 0, 0, 0.8);
}
</code></pre>
<p><strong>Sidebar text colors (selected/active state):</strong></p>
<pre><code class="language-css">.nav-link.active {
    background-color: #000000;
    color: rgb(255, 255, 255);
}
</code></pre>
<h3>Content Colors</h3>
<p><strong>Content background:</strong></p>
<pre><code class="language-css">.main-content {
    background-color: #ffffff;
}
</code></pre>
<p><strong>Content text color:</strong></p>
<pre><code class="language-css">#markdown-content {
    color: inherit;  /* Uses default browser text color */
}
</code></pre>
<p><strong>Content links:</strong></p>
<pre><code class="language-css">#markdown-content a,
#tag-posts-list h2 a,
.post-link,
.post-tags .tag-link {
    color: #0066cc;
    font-weight: 600;
}

#markdown-content a:hover,
#tag-posts-list h2 a:hover,
.post-link:hover,
.post-tags .tag-link:hover {
    color: #0052a3;
}
</code></pre>
<p>All links in your content (blog posts, tag links, post list links) use the same color and weight for consistency.</p>
<h3>Blockquote Colors</h3>
<p>Blockquotes are styled in <code>styles/theme.css</code>:</p>
<pre><code class="language-css">#markdown-content blockquote {
    border-left: 4px solid #0066cc;
    color: #666;
}
</code></pre>
<p>The border color matches your link color by default, but you can customize it.</p>
<h3>Sidebar Footer</h3>
<p>Footer colors are also in <code>styles/theme.css</code>:</p>
<pre><code class="language-css">.sidebar-footer {
    background-color: #000000;
}

.footer-text,
.footer-link {
    color: rgba(255, 255, 255, 0.6);
}

.footer-link:hover {
    color: rgba(0, 0, 0, 0.8);
}
</code></pre>
<h2>Content Spacing</h2>
<h3>Line Spacing</h3>
<p>Content line spacing is controlled in <code>styles/theme.css</code>:</p>
<pre><code class="language-css">.main-content {
    line-height: 1.7;
}
</code></pre>
<p>Adjust this value to make text more or less spaced. Common values:</p>
<ul>
<li><code>1.5</code> - Tighter spacing</li>
<li><code>1.7</code> - Default (comfortable reading)</li>
<li><code>1.8</code> - More breathing room</li>
<li><code>2.0</code> - Very spacious</li>
</ul>
<h2>Quick Theme Examples</h2>
<h3>Light Theme (Default)</h3>
<p>All in <code>styles/theme.css</code>:</p>
<pre><code class="language-css">.sidebar {
    background-color: #f5f5f5;
}

.main-content {
    background-color: #ffffff;
}

#markdown-content a {
    color: #0066cc;
}

.nav-link.active {
    background-color: #000000;
    color: rgb(255, 255, 255);
}
</code></pre>
<h3>Dark Theme</h3>
<p>Edit <code>styles/theme.css</code>:</p>
<pre><code class="language-css">.sidebar {
    background-color: #1a202c;
}

.main-content {
    background-color: #2d3748;
}

#markdown-content {
    color: #e2e8f0;
}

.nav-link {
    color: rgba(255, 255, 255, 0.7);
}

.nav-link:hover {
    background-color: #4a5568;
    color: rgba(255, 255, 255, 0.9);
}

.nav-link.active {
    background-color: #4a5568;
    color: rgb(255, 255, 255);
}

#markdown-content a {
    color: #63b3ed;
}

.sidebar-footer {
    background-color: #1a202c;
}

.footer-text,
.footer-link {
    color: rgba(255, 255, 255, 0.6);
}
</code></pre>
<h3>Blue Theme</h3>
<pre><code class="language-css">.sidebar {
    background-color: #e3f2fd;
}

.nav-link.active {
    background-color: #1976d2;
    color: rgb(255, 255, 255);
}

.nav-link:hover {
    background-color: #bbdefb;
}

#markdown-content a {
    color: #1565c0;
}

#markdown-content blockquote {
    border-left: 4px solid #1976d2;
}
</code></pre>
<h2>Tips</h2>
<ol>
<li><p><strong>Start with <code>theme.css</code></strong>: This file contains 90% of what you&#39;ll want to customize. Edit this first!</p>
</li>
<li><p><strong>Test your changes</strong>: After modifying CSS, run <code>gorky build</code> and check <code>index.html</code> in your browser.</p>
</li>
<li><p><strong>Browser DevTools</strong>: Use your browser&#39;s developer tools (F12) to inspect elements and test color changes in real-time before editing files.</p>
</li>
<li><p><strong>Keep it organized</strong>: All theme-related properties are in <code>theme.css</code> - use that as your main customization file.</p>
</li>
<li><p><strong>Check file comments</strong>: Each CSS file has comments at the top explaining what it controls.</p>
</li>
</ol>
<h2>Need Help?</h2>
<ul>
<li><strong>Check <code>styles/theme.css</code> first</strong> - most customization is there</li>
<li>Read the comments in each CSS file - they describe what each section controls</li>
<li>Use browser DevTools to inspect elements and see which CSS file controls them</li>
<li>Test changes incrementally - change one thing at a time to see the effect</li>
</ul>
</div>
<div id="content-content/getstarted-md" class="content-section" data-title="Get Started" data-description="Learn how to set up and customize your Gorky website" data-keywords="getting started, setup, configuration, tutorial, guide" style="display: none;">
<h1>Get Started with Gorky</h1>
<p>Welcome! This guide will help you set up and customize your Gorky site.</p>
<h2>Quick Start</h2>
<h3>Prerequisites</h3>
<ul>
<li><a href="https://nodejs.org/">Node.js</a> (version 12 or higher)</li>
</ul>
<h3>Installation</h3>
<p>If you haven&#39;t already, install Gorky:</p>
<pre><code class="language-bash">npm install -g gorky
</code></pre>
<p>Or install locally in your project:</p>
<pre><code class="language-bash">npm install --save-dev gorky
</code></pre>
<h3>Building Your Site</h3>
<p>Build your site using the Gorky CLI:</p>
<pre><code class="language-bash">gorky build
</code></pre>
<p>Or use npm:</p>
<pre><code class="language-bash">npm run build
</code></pre>
<p>This generates <code>index.html</code> from your markdown files.</p>
<h2>Configuration</h2>
<h3>Site-Wide Configuration</h3>
<p>Edit <code>site-config.js</code> in your project root to customize site-wide settings:</p>
<pre><code class="language-javascript">module.exports = {
    baseUrl: &#39;https://yourusername.github.io/your-repo&#39;,  // Your GitHub Pages URL
    siteName: &#39;My Site&#39;,                                   // Your site name
    authorName: &#39;Your Name&#39;,                               // Default author name
    defaultDescription: &#39;Your site description...&#39;,       // Default meta description
    defaultKeywords: &#39;keyword1, keyword2&#39;,                 // Default meta keywords
    favicon: &#39;favicon.ico&#39;,                                // Optional: path to favicon
    appleTouchIcon: &#39;apple-touch-icon.png&#39;                 // Optional: path to Apple touch icon
};
</code></pre>
<p>This configuration is automatically injected into your site during the build process.</p>
<p><strong>Important:</strong> Update <code>baseUrl</code> to match your GitHub Pages URL. For example:</p>
<ul>
<li>If your repo is <code>username/my-site</code>, use: <code>https://username.github.io/my-site</code></li>
<li>If your repo is <code>username/username.github.io</code>, use: <code>https://username.github.io</code></li>
</ul>
<p>These settings are also used for:</p>
<ul>
<li>SEO meta tags (title, description, keywords)</li>
<li>Open Graph tags for social media sharing</li>
<li>Canonical URLs</li>
<li>JSON-LD structured data</li>
<li>Author attribution (fallback if posts don&#39;t specify an author)</li>
</ul>
<h3>Sidebar Configuration</h3>
<p>Edit <code>site-config.js</code> to customize your navigation. The sidebar configuration is in the <code>sidebar</code> property:</p>
<pre><code class="language-javascript">module.exports = {
    // ... other config ...
    sidebar: {
        // Sidebar header text (displayed at top of sidebar)
        header: &#39;My Site&#39;,
        
        // Display names for main navigation items
        homeDisplayName: &#39;üè† Home&#39;,
        postsDisplayName: &#39;‚úçÔ∏è Posts&#39;,
        
        // Sidebar footer items (array of text items or links)
        footer: [
            {
                text: &#39;2025 ¬© Your Name&#39;,
                target: &#39;https://yourusername.github.io&#39;
            }
        ],
        
        // Navigation sections (object where keys are section titles, values are navigation items)
        sections: {
            // Empty section name creates items without a section header
            &#39;&#39;: {
                &#39;üìù About&#39;: {
                    target: &#39;?page=about&#39;,
                    openInNewTab: false
                }
            },
            &#39;Links&#39;: {
                &#39;GitHub&#39;: {
                    target: &#39;https://github.com/yourusername&#39;,
                    openInNewTab: true
                }
            }
        }
    }
};
</code></pre>
<p>Navigation items in <code>sections</code> have the format: <code>label: { target: &#39;url&#39;, openInNewTab: boolean }</code>. Use <code>?page=filename</code> for internal pages (without .md extension) or full URLs for external links.</p>
<h2>Post Format</h2>
<p>Post files can have any filename you want. All metadata is defined in YAML frontmatter at the top of each markdown file.</p>
<p>Post metadata is defined in YAML frontmatter at the top of each markdown file:</p>
<pre><code>---
slug: my-first-post
title: My First Post
date: 2025-12-15
tags: blog,tutorial
description: This is a preview of my first post
thumbnail: content/images/my-image.jpg
keywords: keyword1, keyword2
author: Author Name
---

# My First Post

Your content here...
</code></pre>
<p><strong>Required fields:</strong></p>
<ul>
<li><code>slug</code> - Unique identifier for the post (used in URLs like <code>?post=my-first-post</code>)</li>
<li><code>title</code> - The post title</li>
<li><code>date</code> - Publication date (format: YYYY-MM-DD or YYYY-M-D)</li>
</ul>
<p><strong>Optional fields:</strong></p>
<ul>
<li><code>tags</code> - Comma-separated tags (e.g., <code>blog,tutorial</code>) or array format</li>
<li><code>description</code> - Description text shown in the posts listing (also used as meta description for SEO)</li>
<li><code>thumbnail</code> - Thumbnail image path (relative to content root, e.g., <code>content/images/thumb.jpg</code>)</li>
<li><code>keywords</code> - Comma-separated keywords for SEO meta tags</li>
<li><code>author</code> - Author name for the post (falls back to <code>SITE_CONFIG.authorName</code> if not provided)</li>
<li><code>published</code> - Set to <code>false</code> to hide a post (defaults to <code>true</code>)</li>
</ul>
<blockquote>
<p>üí° You can directly visit <code>&lt;URL&gt;?post=slug</code> to land on a specific post.</p>
</blockquote>
<h2>Favicon</h2>
<p>Add a favicon to your site:</p>
<ol>
<li>Create or obtain a <code>favicon.ico</code> file (16x16 or 32x32 pixels)</li>
<li>Place it in your site root (same directory as <code>index.html</code>)</li>
<li>Optionally create <code>apple-touch-icon.png</code> (180x180 pixels) for iOS devices</li>
<li>The favicon will be automatically used (defaults to <code>favicon.ico</code>)</li>
</ol>
<p>To customize the favicon path, edit <code>site-config.js</code> in your project root:</p>
<pre><code class="language-javascript">const SITE_CONFIG = {
    // ... other config
    favicon: &#39;favicon.ico&#39;,              // Path to favicon
    appleTouchIcon: &#39;apple-touch-icon.png&#39;  // Path to Apple touch icon
};
</code></pre>
<h2>Custom Pages</h2>
<p>Any markdown file in the <code>content/</code> directory (not in <code>posts/</code>) can be a custom page. Add frontmatter for SEO:</p>
<pre><code>---
title: About
description: Learn more about this site
keywords: about, information

---

# About

Your page content...
</code></pre>
<p>Link to custom pages from your sidebar by referencing them with <code>?page=filename</code> (without the <code>.md</code> extension). For example, to link to <code>content/about.md</code>, use <code>?page=about</code> in the sidebar configuration in <code>site-config.js</code>.</p>
<blockquote>
<p>üí° You can also directly land on a page using <code>?page=filename</code> in the browser address bar.</p>
</blockquote>
<h2>Project Structure</h2>
<pre><code>my-site/
‚îú‚îÄ‚îÄ content/
‚îÇ   ‚îú‚îÄ‚îÄ home.md              # Your home page content
‚îÇ   ‚îú‚îÄ‚îÄ posts/               # Blog posts directory
‚îÇ   ‚îÇ   ‚îî‚îÄ‚îÄ *.md             # Posts with YAML frontmatter (any filename)
‚îÇ   ‚îú‚îÄ‚îÄ images/              # Images directory
‚îÇ   ‚îî‚îÄ‚îÄ posts.md             # Auto-generated posts listing (don&#39;t edit)
‚îú‚îÄ‚îÄ styles/                  # CSS styling files
‚îú‚îÄ‚îÄ index-template.html      # HTML template (don&#39;t edit, auto-generated from site-config.js)
‚îú‚îÄ‚îÄ index.html               # Generated HTML (auto-generated, don&#39;t edit)
‚îú‚îÄ‚îÄ gorky.config.js          # Optional configuration file
‚îú‚îÄ‚îÄ package.json             # Node.js dependencies
‚îî‚îÄ‚îÄ README.md                # Documentation
</code></pre>
<h2>Deployment to GitHub Pages</h2>
<ol>
<li>Push your code to a GitHub repository</li>
<li>Go to your repository Settings ‚Üí Pages</li>
<li>Select the branch that contains your <code>index.html</code> (usually <code>main</code> or <code>gh-pages</code>)</li>
<li>Your site will be available at <code>https://yourusername.github.io/repository-name</code></li>
</ol>
<p><strong>Tip:</strong> If you want your site at <code>username.github.io</code>, create a repository named exactly <code>username.github.io</code> and set <code>baseUrl</code> in <code>site-config.js</code> to <code>https://username.github.io</code>.</p>
<h2>Optional Configuration</h2>
<p>Create a <code>gorky.config.js</code> file to customize paths:</p>
<pre><code class="language-javascript">module.exports = {
  contentDir: &#39;content&#39;,
  outputFile: &#39;index.html&#39;,
  templateFile: &#39;index-template.html&#39;,
  stylesDir: &#39;styles&#39;
};
</code></pre>
</div>
<div id="content-content/home-md" class="content-section" style="display: block;">
<img src="content/images/sf.jpg" alt="drawing" style="width:40%;float:right;padding:0px 0px 0px 50px"/>

<p>Hi, I&#39;m Vatsalüëã  </p>
<p>I make games, apps, art, tools, and more with the Unity engine. </p>
<h3>What I do</h3>
<p>Presently I am employed at <a href="https://www.managexr.com">ManageXR</a> where I develop our Unity VR application and SDKs. You can see my professional and education background on <a href="https://www.linkedin.com/in/vatsalambastha/">LinkedIn</a>.</p>
<p>My open source work is on <a href="https://www.github.com/adrenak">Github</a>. One of my more popular projects is <a href="https://www.github.com/adrenak/univoice">UniVoice</a> for audio networking in Unity.</p>
<p>Aside from my day job and open source work, I try to always have a game project in progress. You can play the games I have developed games on <a href="https://adrenak.itch.io/?ref=vatsalambastha.com">adrenak.itch.io</a>.</p>
<p>There are some more things that I work on. These projects aren&#39;t dead, I just don&#39;t get to dedicate the amount of time I would like:</p>
<ul>
<li>A <a href="https://www.youtube.com/@VatsalAmbastha?ref=vatsalambastha.com">Youtube channel</a> where I sometimes upload dev logs and UniVoice tutorials. </li>
<li>Sometimes I sketch and post them on Instagram <a href="https://www.instagram.com/brbsketching?ref=vatsalambastha.com">@brbsketching</a>.</li>
<li><a href="https://retroreel.app">Retro Reel</a> which is an Android app for watching classic Hollywood movies in the public domain. It hosts around 2000 movies and has around 200K downloads on Google Play.</li>
</ul>
<h3>This website</h3>
<p>You&#39;ll find here my blog, work, and relevant links.</p>
<p>If you like how this website looks, check out <a href="https://www.github.com/adrenak/gorky">Gorky</a> which is the simple markdown based static site generator I made for this website.</p>
<h3>Contact</h3>
<p>Email me at <code>ambastha.vatsal@gmail.com</code></p>
<p>I&#39;m on Discord. My username is <code>adrenak</code>. You&#39;re welcome to join <a href="https://discord.com/invite/Tnf9KG93MC?ref=vatsalambastha.com">my Discord server</a>, especially if you&#39;re looking for UniVoice help or updates.</p>
</div>
<div id="content-content/posts/2025-03-13--univoice-mono-repo-md" class="content-section" data-slug="univoice-mono-repo" data-date="13 Mar 2025" data-tags="univoice,opensource" data-title="UniVoice is now (almost) a mono repo" data-description="All those separate repos were really slowing everyone down. A few things still exist in separate repos." data-keywords="univoice, unity, voice, voip, vivox, dissonance, open source" style="display: none;">
<p>UniVoice has been around since Jan 2019 and has been evolving towards becoming a robust VoIP solution for Unity. Recently I released version 4.x, which is a big upgrade from v3. One of the things that&#39;s changed is that UniVoice is now a mono repo.</p>
<h2>Why mono repo?</h2>
<p>Previously the main repository only housed the interfaces and implementations for them were <a href="https://github.com/adrenak?tab=repositories&q=univoice&type=&language=&sort=&ref=vatsalambastha.com">separate repositories</a>.</p>
<p>This caused a lot of pain for both me and any users of UniVoice.</p>
<p>For me because if I wanted to change something in, let&#39;s say, the <a href="https://github.com/adrenak/univoice-unimic-input?ref=vatsalambastha.com">univoice-unimic-input repository</a>. I would need to open UniVoice, change the manifest to point to a local copy of the univoice-unimic-input repo so that I can test the changes locally. </p>
<p>For users because when they&#39;d install the univoice package, it wouldn&#39;t really have anything usable. They&#39;d need to install implementation packages separately. In v3, to get UniVoice to work you needed at implementations of at least three interfaces: <code>IAudioInput</code>, <code>IAudioOutput</code> and <code>IChatroomNetwork</code>.</p>
<p>This isn&#39;t readily obvious. The first reason is that there just isn&#39;t enough documentation (something I&#39;ll be working on soon). The second is that unless you know how UniVoice works or examine the inner workings of a sample project (again a separate repository), you probably wouldn&#39;t know UniVoice mainly works using those three interfaces.</p>
<p>So simplification and ease of maintenance were the major motivations for moving all the implementations to the main repository. </p>
<h2>Inbuilt implementations</h2>
<p>Instead of importing packages of implementations, the implementations are now included in the main repository. You can find them <a href="https://github.com/adrenak/univoice/tree/master/Assets/Adrenak.UniVoice/Runtime/Impl?ref=vatsalambastha.com">here</a>.</p>
<p>Working out of the box
First, UniVoice now has package <a href="https://github.com/adrenak/univoice/blob/d76d964e55ab2f8f70efad05bd3f2d1bfc1161e8/Assets/Adrenak.UniVoice/package.json?ref=vatsalambastha.com#L34">dependencies</a>. They include </p>
<ul>
<li><a href="https://github.com/adrenak/brw?ref=vatsalambastha.com">brw</a> the binary reader and writer for network messages</li>
<li><a href="https://github.com/adrenak/unimic?ref=vatsalambastha.com">unimic</a> for easily reading Microphone data at runtime. </li>
<li><a href="https://github.com/adrenak/concentus-unity?ref=vatsalambastha.com">concentus-unity</a> which is a pure C# port of Opus for encoding and decoding audio.
Worth noting is that all the above dependencies are pure C# and themselves only dependent on Unity or standard C#.</li>
</ul>
<p>Using the dependencies above, the following implementations have been written and included in the univoice package out of the box:</p>
<ul>
<li><a href="https://github.com/adrenak/univoice/blob/master/Assets/Adrenak.UniVoice/Runtime/Impl/Outputs/StreamedAudioSourceOutput.cs?ref=vatsalambastha.com">StreamedAudioSourceOutput</a> that implements IAudioOutput to play peer audio. Note that this uses StreamedAudioOutput, which is included in unimic.</li>
<li><a href="https://github.com/adrenak/univoice/blob/master/Assets/Adrenak.UniVoice/Runtime/Impl/Inputs/UniMicInput.cs?ref=vatsalambastha.com">UniMicInput</a> that implements IAudioInput to capture microphone input for sending. This uses the Mic class in unimic</li>
<li><a href="https://github.com/adrenak/univoice/tree/master/Assets/Adrenak.UniVoice/Runtime/Impl/Filters/Concentus%20Opus%20Filters?ref=vatsalambastha.com">Concentus</a> Filters that implement IAudioFilter for encoding and decoding audio. This uses concentus-unity</li>
</ul>
<h2>Requiring some setup</h2>
<p>UniVoice can also have inbuilt implementations that depend on code that&#39;s not included as a package dependencies. Right now, this is the <a href="https://github.com/adrenak/univoice/tree/master/Assets/Adrenak.UniVoice/Runtime/Impl/Networks/Mirror?ref=vatsalambastha.com">Mirror network implementation</a>.</p>
<p>Observe that each file uses the compilation symbol <code>UNIVOICE_MIRROR_NETWORK</code>.</p>
<p>The reason for this is that univoice doesn&#39;t include Mirror by default. So if you want voice chat in a Mirror game, you have to import Mirror and add that compilation symbol.</p>
<p>All future network implementations, let&#39;s say FishNet, Netcode would be added as inbuilt implementations this way. You&#39;d need the supported network solution in your project and add a compilation symbol.</p>
<p>Note that the Mirror implementation also uses brw, which is a package dependency as mentioned above. Chances are all future network implementations would use it to read and write network messages.</p>
<h2>What this means</h2>
<p>Say you want an implementation that depends on external code. Let&#39;s say it&#39;s an <code>IAudioFilter</code> for removing noise from mic input before sending it.</p>
<p>You have a package called com.denoise which has some native library for removing noise from audio data. You add it to your <code>manifest.json</code> as a dependency. Then write DenoiseFilter which would be an implementation of <code>IAudioFilter</code> which uses the code in com.denoise to achieve the filter&#39;s capabilities.</p>
</div>
<div id="content-content/posts/2025-04-14--rnnoise-md" class="content-section" data-slug="univoice-rnnoise" data-date="12 Apr 2025" data-tags="univoice,opensource" data-title="UniVoice 4.2.0  RNNoise noise cancellation" data-description="Just because your mic captures every little thing doesn't mean the other person needs to hear it. Filter that noise!" data-keywords="univoice, unity, voice, voip, vivox, dissonance, open source" data-author="Vatsal Ambastha" style="display: none;">
<p>UniVoice was updated to 4.2.0 recently with the key change being that RNNiose is now supported.</p>
<p>RNNoise is an amazing audio noise removal library that I&#39;ve seen excellent results with. Background noise such as traffic, ambient noise are almost completely gone. </p>
<p>It is available in UniVoice 4.2.0 as an <code>IAudioFilter</code> implementation called <code>RNNoiseFilter</code> and is a one-line integration. <code>RNNoiseFilter</code> class internally uses <a href="https://github.com/adrenak/RNNoise4Unity?ref=vatsalambastha.com">RNNoise4Unity</a>, a repository I made that simply makes it available as a UPM package. </p>
<p>Since RNNoise4Unity uses native libraries, it has not been made a direct dependency of UniVoice. Only a <code>RNNoiseFilter.cs</code> is provided with UniVoice that can be activated using <code>UNIVOICE_FILTER_RNNOISE4UNITY</code> after you import RNNoise4Unity into your project. </p>
<p>Not adding packages that rely on native libraries to UniVoice dependencies is something I&#39;m going to continue. I have highlighted in the <a href="https://github.com/adrenak/univoice/commit/52b4aa6ae1db5d9ec4d4d87ce9230b94989de0fa?ref=vatsalambastha.com#diff-b335630551682c19a781afebcf4d07bf978fb1f8ac04c6bf87428ed5106870f5">4.2.0 commit</a> the following: </p>
<h2>Activating non-packaged dependencies</h2>
<p>UniVoice includes and installs the dependencies mentioned above along with itself. </p>
<p>The following implementations are available out of the box when you install it: </p>
<ul>
<li>Opus encoding/decoding filter (via Contentus-Unity) </li>
<li><code>GaussianAudioBlur</code> filter (plain C#, no dependencies used) </li>
<li>Mic audio capture input (via UniMic) </li>
<li>AudioSource based playback output (via UniMic)</li>
</ul>
<p>But the following implementations are based on dependencies that you have to install and enable via compilation symbols as they are not UniVoice dependencies and don&#39;t get installed along with UniVoice. This is because they are either third party modules or based on native libraries (not plain C#) that can pose build issues. </p>
<ul>
<li>Mirror network:    <ul>
<li>To enable, ensure the Mirror package is in your project and add <code>UNIVOICE_NETWORK_MIRROR</code> to activate it</li>
</ul>
</li>
<li>RNNoise Noise removal filter:    <ul>
<li>To enable, ensure the RNNoise4Unity package is in your project and add <code>UNIVOICE_FILTER_RNNOISE4UNITY</code> to activate it</li>
</ul>
</li>
</ul>
<h2>Usage</h2>
<p>RNNoiseFilter is an input filter, because it is applied to the audio captured at the devices. To use it, simply add this to your integration:</p>
<p><code>session.InputFilters.Add(new RNNoiseFilter());</code></p>
<p>where session is a <code>ClientSession</code> object</p>
</div>
<div id="content-content/posts/2025-04-14--univoice-4-x-x-upgrade-guide-md" class="content-section" data-slug="univoice-4-upgrade-guide" data-date="14 Apr 2025" data-tags="univoice,opensource" data-title="UniVoice 4.x.x upgrade guide" data-description="A lot of things changed and broke between v3 and v4. Here's what you need to know." data-keywords="univoice, unity, voice, voip, vivox, dissonance, open source" data-author="Vatsal Ambastha" style="display: none;">
<p>A lot has changed between UniVoice v3 and v4, however I&#39;ve tried to keep the new things &quot;mirror&quot; some old patterns as much as possible.</p>
<p>There&#39;s no way to upgrade from v3 to v4 without code changes, so getting familiar with some key changes can help.</p>
<p>In this post I&#39;ll be comparing the sample code for v4 and v3 and try to describe the differences that have been made.</p>
<p><a href="https://github.com/adrenak/univoice/blob/master/Assets/Adrenak.UniVoice/Samples/Group%20Chat%20Sample/Scripts/GroupVoiceCallMirrorSample.cs?ref=vatsalambastha.com">v4 sample</a></p>
<p><a href="https://github.com/adrenak/univoice-sample/blob/master/Assets/Scripts/GroupVoiceCallSample.cs?ref=vatsalambastha.com">v3 sample</a></p>
<h2>Namespace changes</h2>
<p>In v3 you&#39;d have noticed these namespaces</p>
<pre><code>Adrenak.UniVoice.UniMicInput 
Adrenak.UniVoice.AudioSourceOutput 
Adrenak.UniVoice.AirPeerNetwork 
</code></pre>
<p>This is a remnant of the previous multi-repo approach where each repo had their own namespaces. UniVoice changed to a mono-repo one as described in an earlier post with the key reason being ease of maintenance and integration.</p>
<p>From v4 onwards, you can expect to need only the following namespaces:</p>
<pre><code>Adrenak.UniVoice.Networks;
Adrenak.UniVoice.Outputs;
Adrenak.UniVoice.Inputs;
Adrenak.UniVoice.Filters;
</code></pre>
<p>With all related implementations being under the same namespace. For example, OpusEncoder, OpusDecoder, RNNoiseFilter are all implementations of <code>IAudioFilter</code> and are under <code>Adrenak.UniVoice.Filters</code> namespace.</p>
<p>This would be the case for &quot;official&quot; implementations. For your own, you of course can use any namespace.</p>
<h2>UniVoice no longer allows you to host, create, join or leave the chatroom</h2>
<p>The <code>IChatroomNetwork</code> interface used to allow you to handle the lifecycle of the network, as seen under the &quot;METHODS&quot; region <a href="https://github.com/adrenak/univoice/blob/2e86a352c9c6ed288ac3c9bc6f147d2345f6d2c2/Assets/Adrenak.UniVoice/Runtime/Interfaces/IChatroomNetwork.cs?ref=vatsalambastha.com">here</a>.</p>
<p>However after v4, UniVoice now only reacts to your network state. It only tells you if the device has connected/disconnected or a peer has connected/disconnected. It does so using the events of the underlying networking plugin. For example, the <code>MirrorClient</code> class, an implementation of <code>IAudioClient&lt;T&gt;</code> internally hooks on to the Mirror events to invoke the events provided by the interface.</p>
<p>This allows you to handle networking via the underlying plugin with univoice never interfering with it. UniVoice only &quot;piggybacks&quot; on the underlying networking plugin to send data.</p>
<h2>ChatroomAgent replaced by ClientSession<T></h2>
<p>Major changes were made to the <code>IChatroomNetwork</code> interface in v3 and it was split into <code>IAudioClient&lt;T&gt;</code> and <code>IAudioServer&lt;T&gt;</code> which allowed implementing the server and client code for a network to be written in two different classes. To handle the lifecycle of a client, the <code>ClientSession</code> class was created which replaces <code>ChatroomAgent</code>.</p>
<p>Notice here: <a href="https://github.com/adrenak/univoice/blob/ab61b04a842d8fcf7c08957bb44f08817ba728ea/Assets/Adrenak.UniVoice/Samples/Group%20Chat%20Sample/Scripts/GroupVoiceCallMirrorSample.cs?ref=vatsalambastha.com#L80">v4</a> vs <a href="https://github.com/adrenak/univoice-sample/blob/65a002b89bf1dab5d2f78f939eb52797eb5d9c57/Assets/Scripts/GroupVoiceCallSample.cs?ref=vatsalambastha.com#L70">v3</a> that their constructions are similar and provide similar events that can subscribe to.</p>
<h2>Filters to change incoming and outgoing audio</h2>
<p>Audio can be processed before it leaves and after it arrives. This has been added as IAudioFilter interface which can be implemented.</p>
<p>In the v4 samples, you can see the Opus encode and decode filters being registered during initialization to ensure that outgoing audio is encoded and incoming audio is decoded properly.</p>
<p>Similarly, a noise filtering filter called <code>RNNoiseFilter</code> has been introduced in version 4.2.0. Read more about it here</p>
<h2>Concluding</h2>
<p>This post along with comparing the v3 and v4 samples, and reading through the comments in the v4 samples is the best way to get familiar with the breaking changes that has been introduced.</p>
</div>
<div id="content-content/posts/2025-04-22-easy-push-to-talk-md" class="content-section" data-slug="univoice-easy-push-to-talk" data-date="22 Apr 2025" data-tags="univoice,opensource" data-title="UniVoice 4.3.0  Easy Push To Talk" data-description="Push to talk saves bandwidth and gives your users more control. These new features save you time when implementing it." data-keywords="univoice, unity, voice, voip, vivox, dissonance, open source" style="display: none;">
<p>Push to Talk is a popular feature to:</p>
<ul>
<li>Give more control to users and allow their audio to be broadcasted only when they want</li>
<li>Reduce CPU and bandwidth usage on both the client and the server</li>
<li>Avoid excess chatter when connected to several peers as they&#39;d all be transmitting audio without it</li>
</ul>
<h2>Old approach using VoiceSettings</h2>
<p>UniVoice provides a <a href="https://adrenak.github.io/univoice/api/Adrenak.UniVoice.VoiceSettings.html?ref=vatsalambastha.com">VoiceSettings</a> class that allows a client to mute or deafen a peer. </p>
<p>In theory, this can be used to create a push-to-talk feature. However this isn&#39;t as straightforward.</p>
<p>After modifying VoiceSettings, you need to call <a href="https://adrenak.github.io/univoice/api/Adrenak.UniVoice.IAudioClient-1.html?ref=vatsalambastha.com#Adrenak_UniVoice_IAudioClient_1_SubmitVoiceSettings">SubmitVoiceSettings()</a> to sync it with the server. The server then makes sure that the audio you send to it doesn&#39;t get sent to anyone.</p>
<p>Usage would be like this:</p>
<pre><code class="language-csharp">session.Client.YourVoiceSettings.deafenAll = true;
session.Client.SubmitVoiceSettings();
</code></pre>
<p>This isn&#39;t too bad, but there are a couple of limitations:</p>
<ul>
<li>Syncing the settings with the server takes a while, so it&#39;s not as instantaneous.</li>
<li>The client still continues to send audio to the server, it&#39;s just that the server doesn&#39;t send it to anyone else which does leads to muting, but this consumes bandwidth on the client and uses the resources of the server.</li>
</ul>
<h2>New approach using ClientSession</h2>
<p>For this reason in version 4.3.0 two new properties have been added to the <code>ClientSession</code> class.</p>
<p>These are:</p>
<ul>
<li>InputEnabled</li>
<li>OutputsEnabled</li>
</ul>
<p>Setting <code>InputEnabled</code> to false would cause the <code>ClientSession</code> to simply ignore the audio that&#39;s being captured on the local device. This means the device doesn&#39;t consume CPU resources running any filters and doesn&#39;t send any audio data over the network, saving bandwidth.</p>
<p>Setting <code>OutputsEnabled</code> to false ignores any incoming audio from other peers. This can be used to mute others easily. However, this doesn&#39;t stop data from being received by the client which still consumes bandwidth. So use this when you need to mute incoming audio instantly and for a short amount of time. Otherwise <code>VoiceSettings</code> is better.</p>
<p>The commit with the code changes is <a href="https://github.com/adrenak/univoice/commit/f6c31d656a102037b8a9cd0bde6d1cdad203d29c?ref=vatsalambastha.com">here</a>.</p>
</div>
<div id="content-content/posts/2025-04-28-drag-and-drop-integration-youtube-md" class="content-section" data-slug="univoice-drag-and-drop-integration" data-date="28 Apr 2025" data-tags="univoice,opensource" data-title="UniVoice 4.4.0  Drag and drop integration (with YouTube tutorial)" data-description="Most UniVoice integration are pretty similar. So just use (or modify) this script." data-thumbnail="content/images/univoice-mirror-basic-tutorial.webp" data-keywords="univoice, unity, voice, voip, vivox, dissonance, open source" style="display: none;">
<iframe width="560" height="315" src="https://www.youtube.com/embed/noDXxmlb9F0" frameborder="0" allow="accelerometer; autoplay; clipboard-write; encrypted-media; gyroscope; picture-in-picture" allowfullscreen></iframe>

<p>I&#39;ve recently helped a lot of people setup a basic UniVoice integration in their projects. And it became clear that the sample scene is not minimal enough.</p>
<p>The sample scene is basically an example app that also does some UI stuff. Going through the code shows how it can be used. But what most people are looking for is to get basic voice chat working as soon as possible. I&#39;ve seen some people adding the example app script to their scenes, which will not work as expected.</p>
<p>For this reason, I have now created a basic setup sample that provides a component that you can just add to your Mirror Network manager and get voice chat working immediately.</p>
<p>This <a href="https://github.com/adrenak/univoice/blob/master/Assets/Adrenak.UniVoice/Samples/Basic%20Setup%20Scripts/UniVoiceMirrorSetupSample.cs?ref=vatsalambastha.com">UniVoiceMirrorSetupSample.cs</a> easily allows you to check if voice chat is working by making sure you have setup UniVoice properly.</p>
<p>The script also provides access to the <code>IAudioServer&lt;T&gt;</code> and <code>IAudioClient&lt;T&gt;</code> objects that can be used for runtime usage like implementing a push to talk mechanism or changing voice settings.</p>
<p>Based on the integration I have helped people do recently, I recommend that a pretty effective way to use UniVoice is to:</p>
<ul>
<li>Have the UniVoice setup run as early as possible in your app/game. Something this component does by running all the setup logic in the Start method. Placing this component on the <code>NetworkManager</code> is generally a good idea.</li>
<li>Providing access to the server and client session objects, in a static or singleton manner. This allows you to work with UniVoice anywhere in your project.</li>
</ul>
<p>Overall, this sample script is all you need for a basic integration. It gives you access to the UniVoice objects to use at runtime. But if you need more control or customization to the setup logic itself, it serves as a good starting point as well.</p>
</div>
<div id="content-content/posts/2025-06-06-morning-thoughts-md" class="content-section" data-slug="morning-thoughts" data-date="6 Jun 2025" data-tags="life" data-title="Morning thoughts of a night owl" data-description="After a decade of inconsistent sleeping habits I finally seem to have found something that works for me." data-keywords="sleep, noctural, insomnia, routine, night shift, remote work" style="display: none;">
<p>The residents in the apartments opposite us have started to turn their lights off and call it a night. Some of them are binge watching TV, and won&#39;t stop for many hours.</p>
<p>The traffic on the road is starting to calm down. Not many passenger cars and cabs now. Most people have already endured their journey back home from their workplace, through the chaotic streets of Bangalore during rush hour. Now it&#39;s largely trucks and cranes and other heavy vehicles making the noise, many of them going to one of the construction sites near us.</p>
<p>My wife and I have had dinner. She&#39;s done with her work and we&#39;re finally watching the series finale of Brooklyn 99, after over a year of watching an episode or two every now and then. There are 11 minutes left before it ends and it&#39;s 10:42pm right now.</p>
<p>Perfect.</p>
<hr>
<p>Because I&#39;d really like to finish this episode before 11pm, which is when I get on Discord to join daily standup and start my workday.</p>
<p>I was recently talking to a couple of people from Czech Republic. Towards the end of the meeting when we were trying to schedule the next call, they asked me what my available hours were. When I told them they paused for a second to do the timezone calculus and were a little puzzled.</p>
<p>I inform them that I work Pacific Time hours, about 11 hours from my local time (depending on daylight savings)</p>
<p>&quot;So you wake up in the afternoon?!&quot;</p>
<p>&quot;Yes, around 3pm. Sometimes as late as 5 if I had some extra work!&quot;</p>
<p>And then they jokingly told me how angry their significant other would be if they had working hours like that.</p>
<hr>
<p>I&#39;ll soon be completing 4 years of working at ManagerXR remotely. I&#39;m in India, most of the team is in the USA and I match my working hours with theirs.</p>
<p>Making games, virtual worlds and other such things leads to pretty interesting conversation when the topic of work comes up. But recently my sleeping habits have stolen some of the limelight.</p>
<p>But despite being a nocturnal person, I enjoy a routine that is pretty consistent, and one that currently feels better than what&#39;s commonly prescribed and followed. </p>
<p>Wake up around 3 pm. </p>
<p>Start work around at 11pm. </p>
<p>Go to sleep around 7am the next day.</p>
<p>That&#39;s 8 hours each for work, life and sleep. </p>
<p>Not everyone gets 8 hours to sleep a day. And not everyone gets to work just 8 hours a day. So I am lucky to have this in the first place.</p>
<p>But what makes it even better is that on most days, between 3pm and 11pm I have 8 straight hours of personal time. Most people have 3-4 hours before work and 3-4 hours after. Even if commute isn&#39;t involved, this halving can be limiting.</p>
<p>For many months now, a big portion of time time has been going towards gym and fitness. I also get to enjoy a nice tea time with my wife right after I wake up, because it&#39;s her lunch break and she works from home too. In the evening, when she&#39;s done with work, we can watch a TV show or go out. I easily have an hour every day to catch up with friends and family over a phone call. </p>
<p>Perhaps if I spent these 8 hours more judiciously, I could make more progress on my side projects. Maybe even get back into playing the guitar or sketching, hobbies that have taken a quiet backseat this year.</p>
<p>In short, 8 hours uninterrupted by sleep or work is pretty amazing. </p>
<hr>
<p>Of course, a big reason I am even able to live this routine is because my wife is around at home to take care of things. </p>
<p>I may go to sleep at 7 in the morning. But before noon my sleep would certainly be ruined by an Amazon delivery and three phone calls unless she&#39;s there to attend them.</p>
<p>Since I was 17, I&#39;ve had what I can only describe as a difficult relationship with the need to sleep. For many years I rebelled against it with the thrill of partying or the rush of working. Or both.</p>
<p>As I type this, I wish I didn&#39;t have to sleep. But it&#39;s 8am already. My eyes are heavy and the morning seems so bright that it hurts when I look outside the window.</p>
<p>Maybe it&#39;s time I close the curtains and go to sleep looking forward to making that cup of tea when I wake up.</p>
</div>
<div id="content-content/posts/2025-07-22--host-mode-md" class="content-section" data-slug="mirror-host-mode-support" data-date="22 Jul 2025" data-tags="univoice,opensource" data-title="UniVoice 4.5.1  Mirror Host mode support" data-description="Because sometimes the server is also a client. Read this for co-op or relay server based games." data-keywords="univoice, unity, voice, voip, vivox, dissonance, open source" style="display: none;">
<p>A limitation of Mirror support in UniVoice so far as been support for Host mode.</p>
<p>The main reason for this is that most teams using UniVoice have been doing so in a dedicated server environment.</p>
<p>However, Host mode has its own uses:</p>
<ul>
<li>makes it much easier to test in Unity. Run the server in the editor and the client on one build.</li>
<li>local networking and co-op experiences.</li>
<li>ParrelSync and other tools can be used to test multiplayer using two editor instances</li>
</ul>
<p>So it only made sense to add support for it. I marked this as an enhancement I want to make in April, but recently there was a lot of activity on the <a href="https://github.com/adrenak/univoice/issues/44?ref=vatsalambastha.com">Github issue</a> so I got to work on it.</p>
<h2>How it works</h2>
<p>The changes are pretty simple. See the commit here </p>
<p>When in Host mode, the server needs to register local client with ID 0 immediately after starting up. This happens in <code>MirrorServer.cs</code> on line 85</p>
<p>When the server stops, or goes from Host to <code>ServerOnly</code> mode, the local client should disconnect. This happens on lines 99 and 90 respectively.</p>
<p><code>MirrorClient.cs</code> needs a minor change. It needs to Unregister the <code>MirrorMessage</code> handler only when it goes from <code>ClientOnly</code> to <code>Offline</code> more. This happens on line 59</p>
<h2>Some thoughts</h2>
<p>I&#39;m still not 100% sure how the <code>RegisterHandler</code> API in Mirror works. You register a handler by providing the listener method, but for unregistering you don&#39;t need it. This makes me think that if you were to register multiple times (which happens right now as it&#39;s done in both <code>MirrorServer</code> and <code>MirrorClient</code>), unregistering from either place would unregister both.</p>
<p>This makes me think that a Mirror message handler utility might be useful that wraps this functionality and adds the ability to unregister a single handler.</p>
<h2>Future Plans</h2>
<p>I plan on making a video showing this very soon.</p>
</div>
<div id="content-content/posts/2025-07-25-proximity-audio-recipe-md" class="content-section" data-slug="univoice-recipe-adding-proximity-audio" data-date="25 Jul 2025" data-tags="univoice,opensource" data-title="UniVoice recipe  Adding proximity audio" data-description="People keep asking me about it, it's achievable and quite simple. Here's a guide!" data-keywords="univoice, unity, voice, voip, vivox, dissonance, open source" style="display: none;">
<p>A bunch of people have asked me how can be achieve proximity audio chat. Which is a fair question given that UniVoice is primarily targeted towards games and they&#39;re often 3D.</p>
<p>Currently proximity audio is not supported out of the box. I do have something under works that would allow you to just drag and drop a component to an avatars head and the audio of players will originate from there. </p>
<p>That said, until that component is ready, it&#39;s possible to get proximity audio using some code.</p>
<h2>Using the OnPeerJoined event</h2>
<p>Look at line 128 of <a href="https://github.com/adrenak/univoice/blob/acc27a96c1e35920f12196899c97d3a59a6e654b/Assets/Adrenak.UniVoice/Samples/Basic%20Setup%20Scripts/UniVoiceMirrorSetupSample.cs?ref=vatsalambastha.com#L128">UniVoiceMirrorSetupSample</a> script that is included in the UniVoice package. </p>
<p>That&#39;s an event that gets invoked for every other player in the game along with their ID. Note that the peer ID is the ID that Mirror assigns, so it can be used using Mirror APIs. This will come in handy later.</p>
<p>Here&#39;s how it works.</p>
<p>Say you join a game that already has 5 players before you, this event will be fired 5 times immediately upon your joining. Now the game has 6 players including you. Later if a 7th player joins, this event will be called again.</p>
<p>The useful thing to note here is that this event gets fired after the audio output for that peer has already been created and placed in the scene. So all you have to do is get that AudioSource and manipulate it to make it proximity audio.</p>
<h2>Finding the AudioSource of a peer</h2>
<p>The first thing you&#39;d need to do it get the output of that peer. You can do it like this:</p>
<p><code>var peerOutput = _session.PeerOutputs[id];</code></p>
<p>This gives you <code>peerOutput</code> which is of <code>IAudioOutput</code> interface type. So we cast it to <code>StreamedAudioSourceOutput</code>. </p>
<p><code>var streamedAudioSourceOutput = peerOutput as StreamedAudioSourceOutput;</code></p>
<p>This gives us an object of type <a href="https://github.com/adrenak/univoice/blob/acc27a96c1e35920f12196899c97d3a59a6e654b/Assets/Adrenak.UniVoice/Runtime/Impl/Outputs/StreamedAudioSourceOutput.cs?ref=vatsalambastha.com">StreamedAudioSourceOutput</a> which is great, because that gives us to access <code>.Stream</code> which is of type <a href="https://github.com/adrenak/unimic/blob/375ba75aeb9d704dd630d9f88bf84f7b7a9765be/Assets/UniMic/Runtime/StreamedAudioSource.cs?ref=vatsalambastha.com">StreamedAudioSource</a>. That then gives us access to .UnityAudioSource which is the actual AudioSource playing the peer audio.</p>
<p>So you could write</p>
<p><code>var peerAudioSource = streamedAudioSourceOutput.Stream.UnityAudioSource;</code></p>
<p>And <em>that</em> object is the AudioSource playing the audio.</p>
<p>By now, we have two key things that we need:</p>
<ul>
<li>We already know the ID of this peer provided by the event</li>
<li>And we just resolved the AudioSource that will play the audio of the peer</li>
</ul>
<p>Now we only need one last thing, the player gameobject of this peer.</p>
<h2>Finding the player gameobject of a peer</h2>
<p>This is where you need to write some code. UniVoice doesn&#39;t know about your games avatars so you need to find the avatar of a peer on a client device. You can do this any way you want, but I&#39;ll just assume you create a method called <code>GetAvatarForPeerID</code> that returns the Transform of the avatar.</p>
<p>Once you have that method, you can call it to get the avatar of the peer</p>
<p><code>var peerAvatar = GetAvatarForPeerID(id);</code></p>
<h2>Attaching the AudioSource to the avatar</h2>
<p>We&#39;re almost done now. We have the AudioSource and we have the avatar that it should be parented to. All you have to do now is move the audio source to the avatar root and turn on spatial audio.</p>
<pre><code>peerAudioSource.transform.SetParent(peerAvatar);
peerAudioSource.transform.localPosition = Vector3.zero;
peerAudioSource.spatialBlend = 1;peerAudioSource.maxDistance = 10;
</code></pre>
<p>I&#39;ve set the max distance to 10 units so the audio will fade out and eventually get quiet when you get out of range.</p>
<h2>Finished code</h2>
<pre><code class="language-csharp">client.OnPeerJoined += id =&gt; {    
  // Get the audio output of the peer    
  var peerOutput = _session.PeerOutputs[id];    
  
  // Cast it to the output implementation we&#39;re using, StreamedAudioSourceOutput 
  var streamedAudioSourceOutput = peerOutput as StreamedAudioSourceOutput;    
  
  // Get the actual Unity AudioSource that is playing the audio of this peer    
  var peerAudioSource = streamedAudioSourceOutput.Stream.UnityAudioSource;    
  
  // Get the avatar of the peer with this ID. You will have to define you own   
  // GetAvatarForPeerID here. Basically, it just needs to get you the transform   
  // of the player prefab for another client. Note that id here is what Mirror   
  // assigns to the client, which should help with this.    
  var peerAvatar = GetAvatarForPeerID(id);    
  
  // Parent and move the peer AudioSource to the avatar so that it moves with it  
  // Then change the AudioSource settings to get proximity audio    
  peerAudioSource.transform.SetParent(peerAvatar);    
  peerAudioSource.transform.localPosition = Vector3.zero;    
  peerAudioSource.spatialBlend = 1;    peerAudioSource.maxDistance = 10;
};
</code></pre>
<p>This is a minimal example to get the idea across.</p>
<p>Mirror does things like destroy player instances when you change the scene. Sometimes it takes a while for the player gameobject to be created when a player joins. All this complexity should be handled in your version of <code>GetAvatarForPeerID</code>. </p>
<p>Making this out of the box is on my to-do list and pretty high priority. </p>
<p>In the meantime if you need help implementing this you can reach out to me on Discord via my ID adrenak or join the Discord server here: <a href="https://discord.com/invite/UwVfMB9SEU?ref=vatsalambastha.com">https://discord.gg/UwVfMB9SEU</a></p>
</div>
<div id="content-content/posts/2025-07-27-metater-thanks-md" class="content-section" data-slug="unimic-metater-thanks" data-date="27 Jul 2025" data-tags="univoice,unimic,opensource" data-title="UniMic 3.3.0  StreamedAudioSource improvements, thanks to Metater@github" data-description="Updates to UniMic that makes playback of real-time streaming audio much better." data-keywords="univoice, unity, voice, voip, vivox, dissonance, open source" style="display: none;">
<p>For a couple of months, I have been getting on a weekly call with a team that&#39;s integrating UniVoice into a project but they&#39;ve been facing an issue.</p>
<p>When it&#39;s just 2 people in the room, they can hear each other perfectly. But as soon as a third person joins, everyone&#39;s audio starts popping and gets a little jittery. You can still understand the person but the audio becomes noisy and irritating after a while.</p>
<p>The popping effect is often the cause of writing audio data to an AudioClip on a buffer strip that&#39;s still being read. Or it can happen when you write data that&#39;s too close to your reading head and before the writing operation completes the read head is already on it.</p>
<p>I&#39;ve been looking into <code>StreamedAudioSource.cs</code> to fix a fix for this. But it was only last week that we finally figured out that the issue is in the Concentus Decode Filter instead and I&#39;ve been looking in the wrong place. </p>
<p>But the great thing about this detour is that during this time I&#39;ve come across how other people are buffering and playing streaming audio. And one of them that does it really well is <a href="https://github.com/Metater/MetaVoiceChat?ref=vatsalambastha.com">MetaVoiceChat by Metater</a>.</p>
<h2>MetaVoiceChat</h2>
<p>The <a href="https://github.com/Metater/MetaVoiceChat/blob/main/Output/AudioSource/VcAudioSourceOutput.cs?ref=vatsalambastha.com">audio playback</a> code in this repository has some abilities I&#39;ve been wanting to add to <code>StreamedAudioSource</code> for the longest time:</p>
<ul>
<li>Better control over buffering</li>
<li>Handling network latency fluctuations</li>
<li>Preventing looping audio</li>
</ul>
<p>I used <code>MetaVoiceChat</code> to make changes to the <code>StreamedAudioSource</code> class and these new features are in <code>unimic@3.3.0</code> now </p>
<p>Here&#39;s what&#39;s been introduced.</p>
<h3>Buffer Controls</h3>
<p>Previously you configured buffering using <code>FrameCountForPlay</code> and <code>BufferFactor</code>. Both of which are pretty confusing. The frame length could be 5ms or 60ms, how am I supposed to configure <code>FrameCountForPlay</code>?</p>
<p>Now you just set a <code>targetLatency</code>. Suppose it&#39;s set to 0.25 seconds. This means the system will accumulate 250ms of audio before starting playback. The <code>targetLatency</code> here is the latency introduced as a result of buffering and is the delay we try to maintain between reception and playback.</p>
<h3>Handling Latency Fluctuations</h3>
<p>But there&#39;s another kind of latency: the delay between transmission and reception.</p>
<p>The transmitting device is sending 1 second of audio every second, be it in chunks of 5ms or 20ms or 60ms. That audio goes over the network to the receiving device which is where network latency is introduced.</p>
<p>In an ideal situation, the network latency will remain constant. If the network latency is 200ms, the receiving device will receive audio in chunks every 200ms. Regardless of chunk size, the receiving device will end up with 1 second of audio every second. The transmission and reception are both in sync with a 200ms delay.</p>
<p>Fluctuations in the network latency means that we don&#39;t receive necessarily receive 1 second of audio every second. When the latency increases, we may receive only 900ms of audio in a second. If the latency reduces, we might receive 1100ms.</p>
<p>The <code>targetLatency</code> acts as a baseline for playback speed adjustment here. </p>
<p>We try to keep the gap between the amount of audio in the buffer and the position of playback at <code>targetLatency</code>.</p>
<p>If we receive audio at less that real-time, say, 900ms of audio over the last 1 second. The gap here will shrink because the playback is faster than the buffer write speed. We react to this by reducing the speed of the playback to increase the gap towards <code>targetLatency</code>.</p>
<p>Similarly, if we receive audio faster than real-time, the gap here would increase. We try to decrease the gap by speeding up the playback.</p>
<p>The speeding up and slowing down of audio is done using a change in pitch. So it does mean the voice will get higher or deeper based on network fluctuations. But this way of handling latency fluctuations is pretty standard and the extent to which the pitch can be change and how fast the pitch changes are both configurable. </p>
<h3>Frame Lifetime</h3>
<p>I don&#39;t think I did any frame expiry before. This could lead to times where a short part of the audio buffer could play repeatedly on a loop.</p>
<p>MetaVoiceChat&#39;s code uses a <code>frameLifetime</code> that allows the system to know when the audio gets outdated and doesn&#39;t play.</p>
<h2>UniVoice support</h2>
<p>At the time of writing, UniVoice 4.5.1 which is the latest version with the <a href="?post=mirror-host-mode-support">newly released Mirror Host mode support</a> used UniMic 3.2.4</p>
<p>I&#39;ll be releasing a 4.6.0 that upgrades the dependency to 3.3.0 and UniVoice users should benefit from these latest improvements.</p>
<h2>Closing thoughts</h2>
<p>MetaVoiceChat does a really great job with audio playback, and I&#39;m glad that the creator Metater was kind enough to give me some tips over Discord.</p>
<p>This is one of the best things about open source software. There are things of mine that Metater has found helpful and vice-versa. It&#39;s back and forth, seeing what other people are doing, often collaborating and trying to create things for everyone to use.</p>
<p>Do <a href="https://github.com/Metater/MetaVoiceChat?ref=vatsalambastha.com">check out MetaVoiceChat here</a>. Something a lot of people may like about it is that unlike UniVoice, it&#39;s very MonoBehaviour friendly and configuration is possible in the inspector instead of via code.</p>
</div>
<div id="content-content/posts/2025-07-29-deepdoor-lore-md" class="content-section" data-slug="deepdoor-lore" data-date="29 Jul 2025" data-tags="gamedev,film" data-title="The missing lore of DEEPDOOR" data-description="This was a pretty short game and left many things unexplained. There was more to it." data-thumbnail="content/images/deepdoor.jpg" data-keywords="game development, unity, DEEPDOOR, itch.io, horror, silence of the lambs, being john malkovich" style="display: none;">
<p>One of the best things about writing a blog is that every now and then I feel like rambling or just typing something that&#39;s on my mind, and I can.</p>
<p>Like <a href="?post=morning-thoughts">Morning thoughts of a night owl</a>, I just start writing and think very little until it&#39;s time to edit. While explaining it to my wife recently, I felt like writing about the lore of <a href="https://adrenak.itch.io/deepdoor?ref=vatsalambastha.com">DEEPDOOR</a>, a short game I released in 2021. </p>
<h2>Development and Release</h2>
<p>Originally meant as a submission for the Haunted PS1 gamejam, I started making DEEPDOOR a few days before the deadline and eventually missed it.</p>
<p>While I did find myself out of the competition due to this, I was having way too much fun making the game. So I spent a couple more days working on it and tweeting updates. One of my posts was noticed by @horrorvisuals and their repost got over 100 likes and maybe 30 new followers. When the game released, in a matter of hours it was in top 50. Over the next few days it went to top 10 and stayed there for a week or so.</p>
<p>Honestly, I was surprised the game got so popular. </p>
<p>It&#39;s unfinished. Made in just around 20 hours. Whatever I did finish is somewhat unpolished. I doesn&#39;t have any real gameplay, you just observe some things and there&#39;s a chase scene. It also doesn&#39;t have a clear ending or a message. </p>
<p>That said, I do think that the core concept (even though it&#39;s not clearly explained) was pretty cool. Of course, it wasn&#39;t conveyed properly in a short, unfinished game. But I think that a larger project around the idea I had would have potential.</p>
<h2>Being John Malkovich</h2>
<p>One of my favorite films is <a href="https://www.imdb.com/title/tt0120601/?ref=vatsalambastha.com">Being John Malkovich</a>. I&#39;ll also be spoiling this movie to a great extent in this blog. So feel free to watch it and read the rest later.</p>
<p>The movie revolves around a depressed and unsuccessful puppeteer named Craig played by John Cusack who begins a sort of dead end job to make ends meet. The office and his co-workers are the first elements that hint at the supernatural and surreal elements of the film. Craig is married, but he gets infatuated by co-worker named Maxine and starts to pursue her.</p>
<p>One day, Craig drops some sheets of paper behind a cabinet. He moves the furniture to find that there&#39;s a tiny door behind it. Curious, he opens the door and sees that inside is a muddy tunnel. He reluctantly crawls inside and gets sucked in. The film then moves to a POV shot of John Malkovich (the actor plays himself in this film) going about his day. Craig realizes that the tunnel leads to John Malkovich&#39;s mind. After around 15 minutes he&#39;s kicked out and emerges from a portal next to a roadway.</p>
<p>Soon Craig and Maxine start monetizing the door. After office hours, they sell 15 minute slots to people who&#39;d queue up for a body swap ride that blends escapism and voyeurism in this compelling way. John Malkovich eventually starts to feel like his mind is being played with. He tracks down this underground business that Craig and Maxine are running and enters the door himself to land in a sort of parallel world where everyone looks like him. This traumatizes him.</p>
<p>It&#39;s also shown that eventually Craig spends so much time inside the door that he no longer gets kicked out and can completely control John, using his acting stardom to launch his puppeteering career.</p>
<h2>The concept</h2>
<p>I&#39;ve watched enough serial killer investigation movies and TV shows to know that it&#39;s physical traces and trails that eventually lead to capture.</p>
<p>Even when the killer is more of a torture sadist than a cold blooded killer (for example in movies like The Poughkeepsie Tapes where the guy kidnapped his victims and kept them captive for years), holding someone hostage eventually creates enough &quot;investigative entropy&quot; that it all comes down in the end.</p>
<p>I&#39;ve often found this super annoying. &quot;How can he be so careless!&quot;. And when the killer is one who never gets caught, it&#39;s always someone very smart and full of themselves and brazen.</p>
<p>There has to be a way, a story with a supernatural torture mechanism that allows a typical, impulsive killer to get away easily. Which is where JBM gave me an idea.</p>
<p>Just like John Malkovich found out about a door that led to his mind, imagine that a serial killer/torturer finds out about his door. When people step into the mind of John, the mind is pretty welcoming. It&#39;s impressionable enough for the visitor to control him to some extent. That&#39;s because JM is a pretty normal person. But what about a person who is very dark, very sinister? You&#39;d imagine that their mind would be hostile. The fantasies of violence probably manifest themselves into visual form that a visitor would encounter. </p>
<p>That&#39;s the core idea of DEEPDOOR. </p>
<h2>My unfinished ideas</h2>
<p>A deep door is just a name I gave to these small doors that lead to someone&#39;s mind.</p>
<p>You play as someone looking into a person&#39;s disappearance. Maybe it&#39;s a friend or a loved one. Or someone you&#39;ve been hired to find. Due to the supernatural and possibly occult nature of what&#39;s happening, the police aren&#39;t exactly taking this seriously. Somehow you find out that a suspect has taken trips to some remote cabin in the woods. You find the door and crawl inside.</p>
<p>Here&#39;s when the game I ended up making departs from the vision I had, largely because that project would have a much larger scope.</p>
<p>What the killer does is, he kidnaps his victims and instead of locking them in a basement or something, he locks them inside the door.</p>
<p>The victims are then inside his mind. The killer, who probably tries to fit in society doing a job, can then torture his victims though just his imagination while he goes about his day. I imagines a massive labyrinth where the victims are locked up in cages and conjured up monsters that he can awake and control to hurt the victims.</p>
<p>You as the player enters the door to find yourself in this labyrinth. It&#39;s ugly and dark and rotting. There are areas that seem to serve no purpose, maybe they are meant for newer things in the future. It&#39;s a fortified labyrinth with monsters you need to steer clear of while being careful to not set something off. You&#39;re in someone else&#39;s mind without their knowledge.</p>
<p>Horror games are secretly puzzle games. You eventually get to the chamber where the victims are held prisoners and tortured in turns by the monsters. You find the person you have been looking for (and more) and need to free them.</p>
<p>Some more ideas I had were:</p>
<h3>Seeing what the killer is seeing</h3>
<p>In Being John Malkovich, you can see through John&#39;s eyes. There&#39;s an episode on Black Mirror called Arkangel which explores a similar ending. I envisioned a curtain on which a film projector shows the killers vision.</p>
<p>When the killer is occupied with his job, let&#39;s say working as a fork-lift operator, that&#39;s when the labyrinth is less alert. You can get away with some things because the minds owner is not paying a lot of attention.</p>
<h3>Opening locked doors and weaponizing what&#39;s inside</h3>
<p>The labyrinth is huge, and there are doors that are locked. There are also secret doors. These are the doors of the mind that contain memories of the killer that are filled with shame or regret. If you manage to open one of these, you&#39;d be able to use what&#39;s inside against the monsters.</p>
<p>I&#39;m not a big fan of creating am explanation of why someone became a serial killer. But I do think that the contents of these locked rooms can be represented in a way that won&#39;t look like you&#39;re sympathizing with a serial killer.</p>
<h3>The killer enters his own down from time to time</h3>
<p>This could be interesting. The killer entering would mean that he sees everyone looking like himself (like John Malkovich did). This might also provide you as the playing character to hide in plain sight as a victim instead of an intruder, because to him everyone has the same faces.</p>
<p>The fact that he likes to enter his own door to torture victims that have the same face as him can be used to highlight his deeply messed up psyche. </p>
<h2>Conclusion</h2>
<p>So, that&#39;s the missing lore of DEEPDOOR. Basically, the thing I had in mind but could not work on. Maybe I&#39;ll make a full game some day. Or maybe I&#39;ll get an email from someone who has picked this idea up.</p>
<p>Either way, hope you liked reading!</p>
</div>
<div id="content-content/posts/2025-08-01-per-peer-output-filters-md" class="content-section" data-slug="univoice-per-peer-output-filters" data-date="1 Aug 2025" data-tags="univoice,opensource" data-title="UniVoice 4.6.0  Per peer output filters" data-description="Each connected peer now has their own filter list. This fixes an Opus decoding bug." data-keywords="univoice, unity, voice, voip, vivox, dissonance, open source" data-author="Vatsal Ambastha" style="display: none;">
<p>UniVoice 4.6.0 is out! The main change in this release is per-peer output filters (instead of global filters) which also fixes a bug. </p>
<p>But before I get into it, there are a couple smaller changes that I&#39;d like to go over:</p>
<h3>UniMic 3.3.0</h3>
<p>UniVoice now uses UniMic 3.3.0. This was a major improvement that I posted about <a href="?post=unimic-metater-thanks">in this post</a> </p>
<h3>ClientSession<T> constructor enhancements</h3>
<p>You no longer need to implement an <code>IAudioOutputFactory</code> the client session object which can now be constructed using a factory method instead</p>
<pre><code class="language-csharp">// This required you to create a StreamedAudioSourceOutput.Factory class that implements IAudioOutputFactory
// even though it doesn&#39;t do much, it just implements Create() that returns a new object
ClientSession = new ClientSession&lt;int&gt;(
  client, 
  input, 
  new StreamedAudioSourceOutput.Factory()
);

// But you you can do this. No need to create the Factory class
ClientSession = new ClientSession&lt;int&gt;(
  client, 
  input, () =&gt; new StreamedAudioSourceOutput()
);
</code></pre>
<p>Probably only useful if you&#39;re making your own <code>IAudioOutput</code> implementations.</p>
<p>Regardless of what you use, <code>ClientSession</code> understands if you&#39;re using a factory object or a method and handles it internally.</p>
<p>This brings me to the main change in this release. </p>
<h2>Per peer output filter</h2>
<h3>Investigation</h3>
<p>I started the post about <a href="?post=unimic-metater-thanks">UniMic 3.3.0</a> with the description of an issue.</p>
<p>When two people are in voice chat, the audio is clear. But as soon as a third person joins, the audio degrades substantially for all users and the voice is crackly. </p>
<p>I have been looking into that issue for over a month. In fact, the improvements that UniMic 3.3.0 introduced were initially me trying to fix this problem. </p>
<p>Around the same time that post went up, Github user <a href="https://www.github.com/filipbarva?ref=vatsalambastha.com">@FilipBarva</a> opened an issue titled &quot;<a href="https://github.com/adrenak/univoice/issues/49?ref=vatsalambastha.com">Robotic voices with more than two clients</a>&quot; which sounded like the root cause was the same.</p>
<p>Turns out the issue is that the Concentus objects, such as decoder, encoder and resampler cannot be shared for the audio of different peers. This is because they probably have some mutable data inside that&#39;s based on what they previously processed. </p>
<p>A while ago I posted this <a href="https://gist.github.com/adrenak/f05b269e46dd3bdc93d3a7b162813d45?ref=vatsalambastha.com">sample concentus test script</a>. It basically does these things (in sequence)- starts the mic and captures the audio frames- resamples the audio to the desired frequency using Concentus, if required- encodes the audio - decodes the audio- plays it back.</p>
<p>You can attach that script to a gameobject, assemble some components in the inspector that it needs and it&#39;ll work. You can do this with multiple gameobjects and they will work in parallel.</p>
<p>I had a suspicion that using the same Concentus objects might lead to problems. So I did something pretty simple, I marked the Concentus objects static so that all instances of this script use the same objects.</p>
<pre><code>static IOpusEncoder encoder;
static IOpusDecoder decoder;
static IResampler resampler;
</code></pre>
<p>And suddenly, the multiple gameobjects that were previously working perfectly in parallel were not sounding so good. The audio had crackles and pops.</p>
<h3>Bug</h3>
<p>Before this release, the <code>ClientSession</code> class had a single <code>List&lt;IAudioFilter&gt; OutputFilters</code>. You can see this in the 4.5.1 release <a href="https://github.com/adrenak/univoice/blob/acc27a96c1e35920f12196899c97d3a59a6e654b/Assets/Adrenak.UniVoice/Runtime/ClientSession.cs?ref=vatsalambastha.com#L45">here</a> and the usage <a href="https://github.com/adrenak/univoice/blob/acc27a96c1e35920f12196899c97d3a59a6e654b/Assets/Adrenak.UniVoice/Samples/Basic%20Setup%20Scripts/UniVoiceMirrorSetupSample.cs?ref=vatsalambastha.com#L188">here</a>.</p>
<p>Basically to add an output filter, you create the filter object and add it to the list.</p>
<p>But this is exactly what was wrong. Internally <code>ClientSession</code> iterated over the same output filters over the audio of every peer. This meant the filters were being shared for different audio streams. </p>
<h3>Fix</h3>
<p>See the <a href="https://github.com/adrenak/univoice/commit/a05c2f5734656984643f9523cd5442338946157c?ref=vatsalambastha.com">4.6.0 commit</a></p>
<p>To fix this, instead of creating and add the filter objects to the <code>ClientSession</code>, you register a lambda that creates and returns the filter object.</p>
<p>This lambda can then be executed for every peer, allowing the session to internally maintain a <code>Dictionary&lt;T, List&lt;IAudioFIlter&gt;&gt;</code> which is a map of every filter for every peer.</p>
<p>The adding and removal of output filters is using using: <code>.AddOutputFilter</code> and <code>.RemoveOutputFilter</code>.</p>
<p>The usage looks like this:</p>
<p><code>ClientSession.AddOutputFilter&lt;ConcentusDecodeFilter&gt;(() =&gt; new ConcentusDecodeFilter());</code></p>
<p><code>ClientSession.RemoveOutputFilter&lt;ConcentusDecodeFilter&gt;();</code></p>
<p>You can also check if an output filter type has already been added using </p>
<p><code>ClientSession.HasOutputFilter&lt;ConcentusDecodeFilter&gt;();</code></p>
<p>The previous usage has been deprecated. Using <code>ClientSession.OutputFilters.Add(new ConcentusDecodeFilter());</code> will now lead to an error that says you should use the new methods. So this release does have some breaking changes.</p>
</div>
<div id="content-content/posts/2025-08-11-client-tags-md" class="content-section" data-slug="univoice-client-tags" data-date="11 Aug 2025" data-tags="univoice,opensource" data-title="UniVoice 4.7.0  Client Tags" data-description="Create chat groups within a chatroom easily. E.g. team voice chat in a 5v5 game" data-keywords="univoice, unity, voice, voip, vivox, dissonance, open source" style="display: none;">
<blockquote>
<p>‚ö†Ô∏è A bug was discovered with Client Tags, this feature is not stable and using it is not recommended. Once identified and fixed, this article will be updated.</p>
</blockquote>
<p>UniVoice 4.7.0 has been released and has a major new feature: Client Tags</p>
<h2>Overview</h2>
<p>Last year, a team using UniVoice had a question. They had 3 scenes in their Unity app that users could travel between. The app used non positional audio. But they didn&#39;t want people in two different scenes to be able to hear or speak to each other.</p>
<p>Consider a VR talent show application with a performer, audience and judges. The judges should be able to hear the speaker and talk to each other, but the speaker should not hear the judges. The audience should be able to listen to the performer. And maybe the performer should be able to hear the audience (applause, cheers, etc)</p>
<p>Similarly, for 5v5 game with a &quot;red&quot; and a &quot;blue&quot; team, I would have to make sure only people on the same team can hear each other so that they can discuss strategies privately.</p>
<h2>VoiceSettings until 4.6.0</h2>
<p>Until version 4.6.0 <a href="https://github.com/adrenak/univoice/blob/6760fb01a69c28e6bdda0800a54854a35e935037/Assets/Adrenak.UniVoice/Runtime/Types/VoiceSettings.cs?ref=vatsalambastha.com">VoiceSettings</a> only allowed to define the following:</p>
<ul>
<li><code>muteAll : bool</code></li>
<li><code>mutedPeers : List&lt;int&gt;</code></li>
<li><code>deafenAll : List&lt;int&gt;</code></li>
<li><code>deafenedPeers : List&lt;int&gt;</code></li>
</ul>
<p>Consider the example of the 3 scenes unity app I mentioned above. If you wanted to use those 4 fields to limit voice chat based on the scene they&#39;re in, a client would need to know which peer is in which room to add to <code>deafenedPeers</code>.</p>
<p>Doing this would require you to write some custom networking code. Maybe a synchronized variable that the server updates. Or some RPCs. There are many ways to do this but it would never be seamless.</p>
<p>The 4 fields above are suitable for only simple scenarios, such as a group voice call app. As soon as you need to group people together based on some criteria, it gets too cumbersome.</p>
<p>Since the <code>VoiceSettings</code> of all peers is stored on the server, so you could write some server code. But one of the core goals of UniVoice is to be very easy to integrate. As soon as you&#39;re having to write server code that&#39;s unrelated to gameplay UniVoice starts to become increasingly intrusive.</p>
<p>Basically, creating voice groups was really frustrating. If only there was a better way.</p>
<h2>VoiceSettings introduces Tags in 4.7.0</h2>
<p>In <a href="https://github.com/adrenak/univoice/blob/05f04805be09362b2d56050ad0668d0f687811fa/Assets/Adrenak.UniVoice/Runtime/Types/VoiceSettings.cs?ref=vatsalambastha.com">version 4.7.0</a>, some new fields are introduced</p>
<ul>
<li><code>myTags : List&lt;string&gt;</code></li>
<li><code>mutedTags : List&lt;string&gt;</code></li>
<li><code>deafenedTags : List&lt;string&gt;</code></li>
</ul>
<p>Each client gets to add a <code>List&lt;string&gt;</code> tags that it wants to be associated with.\ <code>.mutedTags</code> and <code>.deafenedTags</code> allow you to define the tags you don&#39;t want send you audio or receiving your audio.</p>
<p>For the 3 scene unity app example, let&#39;s say the scenes are &quot;Lobby&quot;, &quot;Waiting Room&quot; and &quot;Match&quot;.</p>
<p>Using the tags feature, you can program your client code such that when you enter the Lobby, you set <code>myTags = {&quot;lobby&quot;}</code> and <code>mutedTags = deafenedTags = {&quot;waiting-room&quot;, &quot;match&quot;}</code></p>
<p>Similarly, when you enter the Waiting Room, myTags = {&quot;waiting-room&quot;} and mutedTags = deafenedTags = {&quot;lobby&quot;, &quot;match&quot;}</p>
<p>Note: The tags cannot have a comma. Currently, if you attempt to set a tag with a comma, it will not stop you but you will run into runtime errors. I&#39;ll have some API enhancements that introduce some guardrails and provide ways of settings values with more concise code.</p>
<h2>Closing Thoughts</h2>
<p>Tags are very client code friendly way of creating subgroups of users for both transmission and reception of audio.</p>
<p>One thing to note is that now <code>deafenedPeers</code> and <code>defeanedTags</code> are cumulative. </p>
<p>Suppose ClientA and ClientB are IDs 1 and 2 respectively and have separate tags &quot;abc&quot; and &quot;xyz&quot;. ClientB needs to have 1 in deafenedPeers or/and &quot;abc&quot; in deafenedTags for ClientA to not receive ClientB audio.</p>
<p>My advice would be to use either IDs or tags, not both, unless you really need it.</p>
<p>As always, if you have questions feel free to reach me via email, Discord (my ID is adrenak).</p>
</div>
<div id="content-content/posts/2025-09-04-fishnet-support-md" class="content-section" data-slug="univoice-fishnet-support" data-date="4 Sep 2025" data-tags="univoice,opensource" data-title="UniVoice 4.8.0  FishNet support" data-description="UniVoice has early FishNet support, consider it in beta. Thanks to Frantisek Holubec for the contribution!" data-keywords="univoice, unity, voice, voip, vivox, dissonance, open source" style="display: none;">
<p>UniVoice 4.8.0 is out!</p>
<p>The key change is that FishNetworking is now finally supported. Huge thanks to <a href="https://github.com/FrantisekHolubec?ref=vatsalambastha.com">@FrantisekHolubec</a> for this <a href="https://github.com/adrenak/univoice/commit/fdc3424180d8991c92b3e092b3edb50b6110c863?ref=vatsalambastha.com">code contribution</a></p>
<h2>Technical details</h2>
<p>Looking at the commit, you will see that the FishNet code is very similar to the Mirror implementation. This is not an accident as FishNet has always tried to position itself as a Mirror++ and has many similarities.</p>
<p>Honestly, I like the FishNet APIs a lot more. It&#39;s cleaner, has events for everything that was required, and unlike Mirror it didn&#39;t need any hacks to get working.</p>
<p>A setup sample script has also been made available along with a sample scene that you can simply build and run and get a basic voice chat working.</p>
<p>Look around the <a href="https://github.com/adrenak/univoice/tree/d0bbcfcfef84fa2e114c97db2dfec22984a4e9ea/Assets/Adrenak.UniVoice/Samples/Basic%20Setup%20Scripts?ref=vatsalambastha.com">samples</a> and you will realize that the FishNet and Mirror setup scripts are absolutely identical, except for two lines where we construct client and server objects.</p>
<h2>Thoughts</h2>
<p>Looking at the FishNet implementation/support scripts, it becomes really obvious that there&#39;s a lot of code duplication between Mirror and FishNet.</p>
<p>Part of me wants to address it. By moving code into a single place, the implementation would also get simpler.</p>
<p>However, first, I will wait for at least one more network implementation before I think of doing something like that. The next is Netcode. I already have a somewhat working code for it, and hope it&#39;ll be released some time this month.</p>
<p>Second, I already have a couple of other quality features like proximity voice, voice activity detection, and most importantly acoustic echo cancellation that I would rather focus on.</p>
<p>Third, it&#39;s not just a matter of moving some code into a base class or utilities. I look at things like the binary writer and reader, and I feel that they should be opened up for user defined payload. Or that an install wizard would make it much easier to set up and modify UniVoice in a project.</p>
<p>So, refactors are not exactly on my mind right now. Version 4.x is all about reaching a set of highly desirable features. </p>
</div>
<div id="content-content/posts/2025-09-17-univoice-wavfilewriter-md" class="content-section" data-slug="univoice-wavfilewriter" data-date="17 Sep 2025" data-tags="univoice,opensource" data-title="UniVoice 4.9.0  WavFileWriter and plans for recording features" data-description="Write streaming audio to .wav files. More advanced features to come!" data-keywords="univoice, unity, voice, voip, vivox, dissonance, open source" style="display: none;">
<p>UniVoice 4.9.0 is out, this is a small release which will build up to a large feature set in the future that I want to talk about in this post.</p>
<p>This version just introduces a utility class named <code>WavFileWriter.cs</code> which allows you to feed it real-time audio and when done it will write it to a .wav file</p>
<h2>Future Plans</h2>
<p>As you might guess, this can be implemented in an <code>IAudioFilter</code>, and registered as an input or output filter to record incoming or outgoing audio from any client/peer.</p>
<p>With some more work, my hope it to create a somewhat high level feature called Recordings that will be an API to record voice data. Writing per-peer audio to individual wav files is definitely going to be supported from the very beginning. But I&#39;m also hoping to make it possible to record and save the entire room data in a single file by merging them at runtime.</p>
<p>The plan is to allow quickly configuring UniVoice at a very high level to easily enable recordings, which might look like just setting something to true. </p>
<p>But I also want to give developers the ability to code things at a lower level where you&#39;re maybe creating your own filter implementation and achieving the behaviour you want.</p>
<h2>Use cases</h2>
<p>An example use-case of this would be storing timestamped meeting recordings on the server that is allowing clients to connect and talk. Since recording can also be per peer, you can the merged as well as individual client audio saved!</p>
<p>Similarly, it can also be used to implement a recording feature on the client. You press a button to enable recording and press it again to finish.</p>
</div>
<div id="content-content/posts/2025-10-14-making-detour-md" class="content-section" data-slug="making-detour" data-date="14 Oct 2025" data-tags="gamedev,film" data-title="Making Detour, a short and wholesome supernatural horror game" data-description="I made a game!" data-thumbnail="content/images/detour/1.png" data-keywords="gamedev, game development, unity, unity3d, itch.io, Detour horror game, Twin Peaks, Fargo" style="display: none;">
<p>This post is about a new game I made called Detour! </p>
<iframe frameborder="0" src="https://itch.io/embed/3950754?linkback=true" width="552" height="167"><a href="https://adrenak.itch.io/detour">Detour by adrenak</a></iframe>  

<p><img src="content/images/detour/1.png" alt=""></p>
<blockquote>
<p>THIS POST ALSO HAS SPOILERS FOR THE TV SHOW FARGO SEASON 1 AND 2!  </p>
</blockquote>
<h2>Fargo Season 2</h2>
<p>Sometime in 2020 I was watching the second season of Fargo, the amazing crime anthology series.</p>
<p>Episode 9 has a <a href="https://www.youtube.com/watch?v=1RdEEPH5Rvk">gunfight scene (see 3:45)</a> during which a UFO appears out of nowhere, briefly distracting the character attacking Lou Solverson (played by Patrick Wilson) that allows Lou to shoot him.</p>
<p><img src="content/images/detour/2.png" alt=""></p>
<blockquote>
<p>The scene with the UFO plot twist in Fargo S2E9</p>
</blockquote>
<p>But, this was so unexpected. Fargo is a pretty grounded crime TV show. The first season was about Martin Freeman playing a fumbling and cowardly man gently but fatally hitting his wife on her head with a hammer during a petty argument. He spends the rest of the season evading capture while being pushed to his limits through a series of desperate situations.</p>
<p><img src="content/images/detour/3.png" alt=""></p>
<blockquote>
<p>Martin Freeman in Fargo Season 1</p>
</blockquote>
<p>UFO references are teased throughout season 2. <a href="https://www.reddit.com/r/FargoTV/comments/1c5lurq/a_complete_list_of_every_time_ufos_aliens_or/">This Reddit post</a> does a great job of listing them. But it wasn&#39;t until episode 9 that I pieced it together, the show writers had been foreshadowing a scene like this all along. This same episode has a <a href="https://www.youtube.com/watch?v=Ra5SFTeHhE0&ref=vatsalambastha.com">scene</a> (at 2:05) in a convenience store which has a sticker on the wall with &quot;We are not alone&quot; written on it along with a UFO.</p>
<h2>Violence and elevator music</h2>
<p>It was after watching episode 9 that I thought the combination of a convenience store in a remote location, a murder and UFO activity would be an interesting premise for a game.</p>
<p>I was also thinking about the kind of music convenience store or marts play which is like Muzak.</p>
<p>Movies often interrupt an action intense scene with this kind of music for comedic effect. Think: John Wick fighting off a dozen people, stepping into an elevator with the typical funky elevator music playing, getting out and proceeding the action in another intense scene.</p>
<p><img src="content/images/detour/4.png" alt=""></p>
<blockquote>
<p>This <a href="https://www.youtube.com/watch?v=inb1NxdoKNc&t=51s&ref=vatsalambastha.com">scene from Blues Brothers</a> has action interrupted by ironic elevator music</p>
</blockquote>
<p>And there are scenes where music like this plays while an intense activity happens, usually violent and the scene being shot with a still camera. This often makes that scene more cold, heartless and brutal.</p>
<p>I felt pretty drawn to the idea of something like this happening in a convenience store while music plays. That inspired <a href="https://www.youtube.com/watch?v=WYqxcc6veYQ&ref=vatsalambastha.com">Detour&#39;s opening</a>.</p>
<h2>Initial idea</h2>
<p>The screen starts black with supermarket music playing. You hear footsteps followed by some struggle and screams, and then a gun going off.</p>
<p>Screen fades in. Player is in a convenience store with a shopping list and the owner/cashier is dead.</p>
<p>You pick up the items that you need and get out.</p>
<p>Outside, you see you&#39;re in a very remote location. There&#39;s hardly anything. Just a motel and a gas station next to the store. This small area of limited commerce only exists here to cater to the drivers passing by, probably looking to stop for the night or buy something and keep going.</p>
<p>You are on foot. In the distance you see police sirens and flashes. They&#39;ll take some minutes to get to you. </p>
<p><img src="content/images/detour/5.png" alt=""></p>
<blockquote>
<p>I also wanted the game to have a circular view like this. But I decided not to go ahead with it. I still think it can be a nice look for some other game.</p>
</blockquote>
<p>You start to walk around. There&#39;s no one at the gas station. All rooms in the motel are locked.</p>
<p>There&#39;s only one direction you can go in. The one opposite to where the cops are coming from. It&#39;s a road that goes through the woods.</p>
<p>As you walk towards the forest, a humming noise starts to grow loud. It&#39;s not the police sirens, it&#39;s something else. From behind the tall trees in front of you emerges a huge UFO with a beam of light shooting on the ground. It starts to move towards you. No matter where you run it keeps following you and finally catches you and the scene fades to black.</p>
<p>It&#39;s clear that you, the player, have been abducted. Dialogs appear. </p>
<p>&quot;Did you get everything?&quot;<br>&quot;Almost&quot;<br>&quot;Almost?&quot;<br>&quot;Yes, I forgot the cake&quot;<br>&quot;Are you serious? And what&#39;s all this blood?&quot;<br>&quot;That&#39;s the cashiers...&quot;<br>&quot;WHAT?? Are you f***ing kidding me?&quot;  </p>
<p>Proceed to have a verbal argument. It is revealed that you, a male alien and you wife/gf are on a road (space?) trip to somewhere. You&#39;d gone to the store to pick up some snacks in the middle of the trip and she really wanted the cake. You shot the cashier by mistake as he tried to tackle you, because, of course he was scared of you.</p>
<p>A pretty typical couple fight, probably something you&#39;d see Martin Freeman and his wife in Fargo season 1 engage in. You as the player go through this argument and at the end they reach just enough of a truce to stop fighting and go ahead with your travels in silence and resentment and the game ends.</p>
<p>So, it was basically a little walking simulator where you are playing thinking you&#39;re a violent criminal and the ending reveals what&#39;s really happening.</p>
<h2>Giving up and rethinking the idea</h2>
<p>Now, I had this idea in 2021. I had recently made and release <a href="https://adrenak.itch.io/deepdoor?ref=vatsalambastha.com">DEEPDOOR</a> which somehow became somewhat popular. You can read more about DEEPDOOR <a href="?post=deepdoor-lore">here</a>.</p>
<p>It was around that time that I started working at ManageXR and was busy and excited about new beginnings there. The Detour idea took a backseat. A &quot;some day&quot; project even though it wasn&#39;t a lot of work.</p>
<p>Some time later I also met my wife and the idea of making a game about a bickering couple that&#39;s hostile towards each other didn&#39;t seem like the best idea during the early days of us knowing each other. </p>
<p>This was until a few months later when I was telling her about the idea and I realized the alien couple could be supportive. Which is when I knew, I can make a <em>wholesome</em> game.</p>
<p><img src="content/images/detour/6.png" alt=""></p>
<blockquote>
<p>I&#39;m not sure if the idea occurred to me while we were having tea. But here&#39;s some tea I made.</p>
</blockquote>
<p>How about changing the game to feature an alien couple talking about snacks, baking and gossip? Needless to say, these dialogs are inspired by how my wife and I talk.</p>
<h2>Twin Peaks</h2>
<p>Despite this new take on Detour, I wasn&#39;t really working on it. The time I had outside my job at ManageXR I largely spent on my open source project UniVoice.</p>
<p>Then David Lynch passed away in January 2025, and for months I had been thinking of watching his iconic TV show, Twin Peaks. We started watching it in May 2025.</p>
<p>We absolutely binged that show. For days all we could talk about was that show. We read about it online, the fan theories, the hidden meanings. We were even dreaming about it in our sleep. The town of Twin Peaks felt like a place I know.</p>
<p><img src="content/images/detour/7.png" alt=""></p>
<blockquote>
<p>The mountains, trees and winding roads of Twin Peaks</p>
</blockquote>
<p>With this came a lot of David Lynch interviews and fan videos in my YouTube video recommendations. Every couple of years I go into a Lynch rabbit hole, listening to him talk about creativity and his process. But this time it was different. And I felt like working on my idea.</p>
<p>So then I started.</p>
<h2>Going with the flow</h2>
<p>I started making the map using whatever free assets and open source I could find on the asset store. I did buy a paid terrain plugin called <a href="https://assetstore.unity.com/packages/tools/terrain/atlas-terrain-editor-207568?ref=vatsalambastha.com">Atlas</a> that I&#39;ve wanted to try for a while. Although, I&#39;m not very happy with it. <a href="https://assetstore.unity.com/packages/tools/terrain/microverse-core-collection-232976?ref=vatsalambastha.com">MicroVerse</a> seems like a much better solution if you&#39;re looking for an alternative.</p>
<p><img src="content/images/detour/8.png" alt=""></p>
<blockquote>
<p>Some terrain design work at ManageXR helped me brush up my world building skills.</p>
</blockquote>
<p>It was around that time that I had been working on <a href="https://www.linkedin.com/feed/update/urn:li:activity:7338214619523534848/?ref=vatsalambastha.com">ManageXR&#39;s official 3D environment</a> which also has a terrain and foliage, which greatly affected how the Detour map looked.</p>
<p>The initial plan was to be pixel-y and PS1-ish. But I decided to go with somewhat high fidelity lighting and post processing. The models themselves were relatively low poly and I didn&#39;t use much specular materials. The idea was to achieve a mid 2000s graphics style.</p>
<p>I did use billboard trees which were lightmapped with a very very very low lightmap resolution, so I could have hundreds of them. The final result ended up looking somewhat like Source Engine. Here&#39;s a nice X page for <a href="https://x.com/sourcepics?lang=en&ref=vatsalambastha.com">Source Engine Aesthetics btw</a></p>
<p><img src="content/images/detour/9.png" alt=""></p>
<blockquote>
<p>The Source Engine look in purely accidental. I love it!</p>
</blockquote>
<p>With no game design document, the entire game was completely improvised.</p>
<p>There&#39;s a pond with still water. I actually had no plans to add a pond, but when I was making the terrain using some heightmap stamps of Atlas, I ended up with a crater-like formation by mistake. At first I thought I&#39;ll fill it densely with trees and have a bonfire at the bottom to attract the user. But I think I couldn&#39;t find any free bonfire assets I was happy with and I instead made it into a pond.</p>
<p><img src="content/images/detour/10.png" alt=""></p>
<blockquote>
<p>Fog, darkness and a wooden bridge on the verge of collapse.</p>
</blockquote>
<p>I thought I had finished the game, but I realized that the &quot;happy path&quot; of the gameplay is too linear and straightforward. But at the same time people did get confused about where they need to go. So I added a mobile home that you can enter to get some hints and also add to the backstory of what&#39;s happening in this small time.</p>
<p>I added some references to Twin Peaks, specifically the main character Dale Cooper. This included his love for coffee, a tape recorder with an 11Labs voice that somewhat resembles Kyle MacLachlan&#39;s where he starts off talking about his investigation but then goes into minute detail about the kind of suit he wants. Classic Dale!</p>
<p>After you have everything, you pass the lake and go up the hill you find a transformer. Interacting with it causes loud thunder and lightning. Streaks of electricity emerge from some lamp poles and reach toward the sky. And there&#39;s a loud rumble like an earthquake. </p>
<p>A giant UFO emerges from behind the hills which moves towards you. It stops right above the center of the pond. When you walk to the spot right below the UFO, the screen goes black. </p>
<p>Dialogs appear. Screen fades in. Music fades in. You see two aliens sitting in a UFO talking. The dialogs reveal that you&#39;re just a pretty decent alien who wanted to buy some snacks for your trip.</p>
<h2>Lessons drawn</h2>
<p>Lately a lot of people have made some good arguments about making small games. Games that don&#39;t take too long to make or play.</p>
<p>What I love about these games is that I know I&#39;d not be maintaining it and that it won&#39;t get too complicated. When I feel something doesn&#39;t make sense, I can even turn an idea completely on its head and move on. It&#39;s like the game develops in front of you.</p>
<p>From a developer/designer point of view, I had fun with the improvised nature of this project. The code was written with full knowledge that it&#39;ll be thrown away. Although between DEEPDOOR and Detour, there is some code I can polish and make it a part of my toolkit.</p>
<p>Visually I think I managed to make it a LOT better looking that I thought I could. For a small itch.io game, I&#39;m pretty happy with how it looks!</p>
</div>
<div id="content-content/posts/2025-10-23-simple-vad-md" class="content-section" data-slug="univoice-simple-vad" data-date="23 Oct 2025" data-tags="univoice,opensource" data-title="UniVoice 4.10.0 SimpleVadFilter" data-description="Simple Voice Activity Detection to reduce bandwidth usage." data-keywords="univoice, unity, voice, voip, vivox, dissonance, open source" style="display: none;">
<p>UniVoice hasn&#39;t had any VAD (Voice Activity Detection) so far. So unless you&#39;re using Push to Talk (see <a href="?post=univoice-easy-push-to-talk">this article</a> on how to use it in UniVoice), your client is constantly transmitting silent audio over the network.</p>
<p>This definitely adds a lot to bandwidth usage. Consider a scenario where two people talk for 1 minute. Assuming they don&#39;t talk over each other, together they will end up sending at least 1 minute of silence over the network.</p>
<p>Make that 3 people, and you have 2 minutes of silence being sent over the network.</p>
<p>I&#39;m not 100% sure but I think that Opus does compress silence more compared to audio with voice. However this is still a big waste of bandwidth.</p>
<h2>SimpleVad</h2>
<p>There are better VAD solutions out there, but they&#39;re C++ code that I need to build. For now I have a plain C# solution. I&#39;ve had a help from ChatGPT making this, but after a day of testing, tweaking and modifying the code I&#39;ve finally reached something I&#39;m happy with.</p>
<p>An <code>IAudioFilter</code> implementation called <code>SimpleVadFilter</code> in <code>SimpleVad.cs</code> has been added in UniVoice 4.10.0</p>
<p>The usage is really simple, you just add a filter to outgoing audio like this:</p>
<p><code>ClientSession.InputFilters.Add(new SimpleVadFilter(new SimpleVad()));</code></p>
<p>It&#39;s probably better to add this filter after RNNoiseFilter so VAD is processing audio with less background noise and more voice.</p>
<p>You can create <code>new SimpleVad()</code> with no parameters, or pass a <code>SimpleVad.Configobject</code> in the constructor. See the <a href="https://adrenak.github.io/univoice/api/Adrenak.UniVoice.SimpleVad.Config.html?ref=vatsalambastha.com">API reference for SimpleVad.Config</a> for more info.</p>
<h2>SimpleVadFilter</h2>
<p>As I said, much of this code is written by ChatGPT, but it&#39;s pretty easy to understand. Here is an explainer for how the algorithm works (this too is AI generated)</p>
<h3>Config</h3>
<p>üéöÔ∏è <strong>Frame Length</strong>
Defines how often we evaluate speech.
20 ms is common for low-latency audio pipelines.</p>
<p>‚ö° <strong>Attack / Release</strong>
Time-based smoothing that prevents jittery on/off behavior.</p>
<ul>
<li>AttackMs: how long sustained speech must last to trigger speaking.</li>
<li>ReleaseMs: how long silence must persist before flipping off.</li>
</ul>
<p>üîä <strong>SNR Thresholds</strong>
Two thresholds create hysteresis:</p>
<ul>
<li>SnrEnterDb (e.g., 10 dB): harder to start speaking.</li>
<li>SnrExitDb (e.g., 4 dB): easier to stay speaking once started.</li>
</ul>
<p>This asymmetry prevents flicker when the signal hovers near the boundary.</p>
<p>ü™ü <strong>Grace Periods</strong></p>
<ul>
<li>MaxGapMs allows brief quiet moments (pauses between words) while still treating it as speech.</li>
<li>NoDropWindowMs ensures that once speech starts, it won‚Äôt instantly cut off.</li>
</ul>
<p>üîâ <strong>Noise Floor</strong>
An exponentially moving average (EMA) tracks background noise:</p>
<ul>
<li>Updates faster when silent (to adapt quickly),</li>
<li>Slower during speech (to avoid raising the floor).</li>
</ul>
<h3>Algorithm</h3>
<p>The main processing happens in ProcessOneFrame()</p>
<p>1Ô∏è‚É£ <strong>Compute RMS Energy</strong>
Each frame‚Äôs RMS (root mean square) gives a measure of loudness:</p>
<p><code>rms = sqrt(sum(s¬≤) / N)</code></p>
<p>It‚Äôs clamped to a minimum <code>EnergyFloor</code> to avoid log(0) issues.</p>
<p>2Ô∏è‚É£ <strong>Compute SNR in dB</strong>
We compare the frame‚Äôs energy to the running noise estimate:</p>
<p><code>snrDb = 20 * log10(rms / noise)</code></p>
<p>A high SNR means the signal is louder than background noise ‚Äî likely speech.</p>
<p>3Ô∏è‚É£ <strong>Apply Threshold and Hysteresis</strong>
Depending on whether we‚Äôre currently speaking:</p>
<pre><code class="language-csharp">threshold = IsSpeaking ? SnrExitDb : SnrEnterDb;
bool rawSpeech = snrDb &gt;= threshold;
</code></pre>
<p>This gives us an initial speech/silence decision per frame.</p>
<p>4Ô∏è‚É£ <strong>Update Noise Floor</strong>
Noise floor adapts using an exponential moving average:</p>
<pre><code class="language-csharp">alpha = rawSpeech ? MaxNoiseUpdateRate : NoiseUpdateRate;
_noiseRms = (1 - alpha) * _noiseRms + alpha * rms;
</code></pre>
<p>That means noise updates quickly when we‚Äôre quiet, but very slowly when we‚Äôre talking ‚Äî preventing voice from polluting the background estimate.</p>
<p>5Ô∏è‚É£ <strong>Gap Handling</strong>
If we‚Äôre in the ‚Äúspeaking‚Äù state but detect brief quiet periods:</p>
<pre><code class="language-csharp">if (IsSpeaking) {
    if (rawSpeech) _gapMs = 0;
    else _gapMs += frameDurationMs;
}
</code></pre>
<p>As long as <code>_gapMs</code> stays below <code>MaxGapMs</code>, we still treat it as continuous speech.</p>
<p>6Ô∏è‚É£ <strong>Time-Based Decision Logic</strong>
Attack, release, and no-drop timers smooth transitions:</p>
<pre><code class="language-csharp">if (!IsSpeaking &amp;&amp; _speechMs &gt;= AttackMs)
    newIsSpeaking = true;

if (IsSpeaking &amp;&amp; _silenceMs &gt;= ReleaseMs &amp;&amp; _sinceOnsetMs &gt;= NoDropWindowMs)
    newIsSpeaking = false;
</code></pre>
<p>This means:</p>
<ul>
<li>We only start speaking after continuous speech.</li>
<li>We only stop speaking after sustained silence.</li>
</ul>
<h2>Some thoughts</h2>
<p>There is still one small limitation to this.</p>
<p>SimpleVad requires, say, 20ms of voice before it turns on. This means that in VAD mode when you start speaking, the first 20ms of your voice will not be transmitted.</p>
<p>I need to work on a way to allow <code>IAudioFilter</code> to either return multiple <code>AudioFrame</code> objects or return the <code>AudioFrame</code> with a longer samples array.</p>
<p>But still, I&#39;m pretty happy with the results. As always, I look forward to your feedback. <a href="https://discord.com/invite/Tnf9KG93MC?ref=vatsalambastha.com">Click here to join the Discord server</a></p>
</div>
<div id="content-content/posts/2025-11-19-oasis-australia-md" class="content-section" data-slug="oasis-in-australia" data-date="19 Nov 2025" data-tags="life,travel" data-title="Oasis reunion and a year with (almost) no social media" data-description="The great wait is over." data-thumbnail="content/images/oasis-australia.jpg" data-keywords="oasis, band, concert, australia, oasis live '25, sydney, rock and roll" style="display: none;">
<img src="content/images/oasis-australia.jpg" style="width: 100%;">

<p>In August 2024, Oasis, my favorite band dropped some unexpected news. They announced a reunion tour 15 years after they broke up in 2009.</p>
<p>If you haven&#39;t heard of Oasis, you may have heard their hits like Wonderwall, Champagne Supernova and Don&#39;t Look Back in Anger. It&#39;s chiefly founded by two brothers Noel and Liam Gallagher, who have always had a strained relationship and have been quite vocal about them not getting along.</p>
<p>While they both have had some great solo albums since the Oasis days, like all fans I too have been looking forward to them burying the hatchet and coming back together. Rumors have floated for years, people interpreting their tweets and lyrics from their new songs to figure out what&#39;s going on between them.</p>
<p>But finally it happened.</p>
<p>The tickets went on sale on 31st August 2024 and like tens of millions of people I too lined up on Ticketmaster online queues to get my hands on them. But after 6 hours of waiting and the site becoming unresponsive a handful of times, I got to know that the tickets were all gone.</p>
<hr>
<p>Saddened, I comforted myself with the possibility of the band getting back together for good and not just for the reunion tour. Maybe they would also release new songs? And even if they don&#39;t, I would certainly get to see phone recordings of the concerts on Youtube, right?</p>
<p>Scalpers were reselling tickets for thousands. I actually saw some for up to $8000 on Stubhub. But the band management was quick to declare that unauthorized resales would not be accepted for entry. Joining scalpers in the action were the scammers looking to sell you a QR code that probably linked to a grocery store or something on Google maps.</p>
<p>Of course as a top 0.05% Oasis listener on Spotify (a figure that doesn&#39;t take into account time spent listening to Oasis on Youtube), my Instagram feed has always been full of Oasis clips: Interviews, concerts, montages, edits and more.</p>
<p>And now these posts were full of comments by people saying that they managed to get tickets and how they had a dozen of their friends logging into Ticketmaster to help increase their odds.</p>
<p><code>Yay good for you Pete! /s</code></p>
<hr>
<p>After a week of Oasis fans showing up every time I opened Instagram, I did the only thing I could to stop getting bummed out constantly: I deleted Instagram from my phone.</p>
<p>I had done this many times before. Sometimes after an embarrassing screen time report. Or after reading about studies on social media usage. Or the times I slumped into my chair watching reels until my back felt weird.</p>
<p>But nothing really made me stick to an Instagram-free life like not getting the tickets.</p>
<p>Without Instagram I suddenly felt that I could actually do things during the afternoons and evenings instead of watching reels on my feed or the ones my friends sent me.</p>
<p>I started going to the gym after half a decade, and really got into it.
I began working on maintaining UniVoice, my popular voice chat plugin for Unity.
I picked up and completed a short game project I had briefly worked on in 2021 and abandoned.</p>
<p>And some more constructive use of time that has made 2025 an amazing year.</p>
<hr>
<p>Months later, I saw that resale tickets through official channels were available for the Australia dates.</p>
<p>I managed to get two of the handful decent seats remaining.</p>
<p>And while we really cut it close, my wife and I got the visa just in time to book a last minute flight to Sydney and watch Oasis live on 8th November with 80000 other people.</p>
<p>An amazing night and a dream come true to watch them live!</p>
</div>
<div id="content-content/posts/2025-12-31-new-website-md" class="content-section" data-slug="github-workflows-for-upm" data-date="31 Dec 2025" data-tags="opensource" data-title="Some Github workflows for UPM repositories" data-description="Making life a little easier." style="display: none;">
<p>I recently made some changes to <a href="https://github.com/adrenak/brw">BRW</a> and added some Github workflows to make life easier maintaining UPM repositories.</p>
<p>They&#39;re all currently standalone. I haven&#39;t figured out how I can &quot;invoke&quot; other workflows from a main workflow. So except for one, all others are manually triggered. Of course, you can merge them all into a single workflow file. Or introduce some ways to ensure they run in the order you want.</p>
<p>You can find the workflows <a href="https://github.com/adrenak/brw/tree/master/.github/workflows">here</a>. In case they change in the future, here they are.</p>
<details>
<summary>npm-publish.yaml</summary>

<p>I added this file because currently I publish <em>locally</em> from my desktop. This requires me to checkout the <code>upm-latest</code> branch, do a <code>git clean -df</code> so I only have the package contents, and then invoke <code>npm publish</code>.</p>
<pre><code class="language-yaml"># Github action that can be triggered to make an npm release
# You need a secret on Github called NPM_PUBLISH_TOKEN
# Configure RELEASE_BRANCH to match the name of the branch that has package.json as the root

name: Publish to NPM

on:
  workflow_dispatch:

env:
  RELEASE_BRANCH: upm-latest

jobs:
  publish:
    runs-on: ubuntu-latest
    permissions:
      contents: read
    
    steps:
      - name: Checkout upm-latest branch
        uses: actions/checkout@v4
        with:
          ref: ${{ env.RELEASE_BRANCH }}
          fetch-depth: 0

      - name: Setup Node.js
        uses: actions/setup-node@v4
        with:
          node-version: &#39;20&#39;
          registry-url: &#39;https://registry.npmjs.org&#39;
        env:
          NODE_AUTH_TOKEN: ${{ secrets.NPM_PUBLISH_TOKEN }}

      - name: Configure npm authentication
        run: |
          npm whoami
      - name: Publish to npm
        run: npm publish
</code></pre>
</details>

<details>
<summary>update-version.yaml</summary>

<p>Sometimes I just forget to update package.json</p>
<p>This is very annoying.</p>
<p>So this file allows me to trigger a version update.</p>
<pre><code class="language-yaml"># Github action that can be triggered to update the version in package.json
# Allows you to define values like major.minor.patch and if that should be set as the new version of incremented
# Set PACKAGE_JSON_PATH based on your repo 

name: Update Package Version

on:
  workflow_dispatch:
    inputs:
      major:
        description: &#39;Major version number&#39;
        required: true
        type: number
        default: 0
      minor:
        description: &#39;Minor version number&#39;
        required: true
        type: number
        default: 0
      patch:
        description: &#39;Patch version number&#39;
        required: true
        type: number
        default: 0
      update_method:
        description: &#39;Update method&#39;
        required: true
        type: choice
        options:
          - increment
          - set
        default: &#39;set&#39;

env:
  PACKAGE_JSON_PATH: Assets/Adrenak.BRW/package.json

jobs:
  bump-version:
    runs-on: ubuntu-latest
    permissions:
      contents: write
    
    steps:
      - name: Checkout repository
        uses: actions/checkout@v4
        with:
          token: ${{ secrets.GITHUB_TOKEN }}
          fetch-depth: 0

      - name: Configure Git
        run: |
          git config user.name &quot;github-actions[bot]&quot;
          git config user.email &quot;github-actions[bot]@users.noreply.github.com&quot;
      - name: Read current version
        id: current-version
        run: |
          if [ ! -f &quot;${{ env.PACKAGE_JSON_PATH }}&quot; ]; then
            echo &quot;Error: package.json not found at ${{ env.PACKAGE_JSON_PATH }}&quot;
            exit 1
          fi
          
          CURRENT_VERSION=$(node -p &quot;require(&#39;./${{ env.PACKAGE_JSON_PATH }}&#39;).version&quot;)
          echo &quot;current_version=$CURRENT_VERSION&quot; &gt;&gt; $GITHUB_OUTPUT
          echo &quot;Current version: $CURRENT_VERSION&quot;
          
          # Parse version components
          IFS=&#39;.&#39; read -r CURRENT_MAJOR CURRENT_MINOR CURRENT_PATCH &lt;&lt;&lt; &quot;$CURRENT_VERSION&quot;
          echo &quot;current_major=$CURRENT_MAJOR&quot; &gt;&gt; $GITHUB_OUTPUT
          echo &quot;current_minor=$CURRENT_MINOR&quot; &gt;&gt; $GITHUB_OUTPUT
          echo &quot;current_patch=$CURRENT_PATCH&quot; &gt;&gt; $GITHUB_OUTPUT
      - name: Calculate new version
        id: new-version
        run: |
          CURRENT_MAJOR=${{ steps.current-version.outputs.current_major }}
          CURRENT_MINOR=${{ steps.current-version.outputs.current_minor }}
          CURRENT_PATCH=${{ steps.current-version.outputs.current_patch }}
          
          INPUT_MAJOR=${{ inputs.major }}
          INPUT_MINOR=${{ inputs.minor }}
          INPUT_PATCH=${{ inputs.patch }}
          UPDATE_METHOD=&quot;${{ inputs.update_method }}&quot;
          
          if [ &quot;$UPDATE_METHOD&quot; = &quot;increment&quot; ]; then
            # Increment mode: add values to current version
            NEW_MAJOR=$((CURRENT_MAJOR + INPUT_MAJOR))
            NEW_MINOR=$((CURRENT_MINOR + INPUT_MINOR))
            NEW_PATCH=$((CURRENT_PATCH + INPUT_PATCH))
            
            # Validate no negative values
            if [ $NEW_MAJOR -lt 0 ] || [ $NEW_MINOR -lt 0 ] || [ $NEW_PATCH -lt 0 ]; then
              echo &quot;Error: Version cannot be negative. Result would be: $NEW_MAJOR.$NEW_MINOR.$NEW_PATCH&quot;
              exit 1
            fi
          else
            # Set mode: use input values directly
            NEW_MAJOR=$INPUT_MAJOR
            NEW_MINOR=$INPUT_MINOR
            NEW_PATCH=$INPUT_PATCH
            
            # Validate no negative values
            if [ $NEW_MAJOR -lt 0 ] || [ $NEW_MINOR -lt 0 ] || [ $NEW_PATCH -lt 0 ]; then
              echo &quot;Error: Version cannot be negative. Input: $NEW_MAJOR.$NEW_MINOR.$NEW_PATCH&quot;
              exit 1
            fi
          fi
          
          NEW_VERSION=&quot;$NEW_MAJOR.$NEW_MINOR.$NEW_PATCH&quot;
          echo &quot;new_version=$NEW_VERSION&quot; &gt;&gt; $GITHUB_OUTPUT
          echo &quot;New version: $NEW_VERSION&quot;
      - name: Update package.json
        run: |
          NEW_VERSION=&quot;${{ steps.new-version.outputs.new_version }}&quot;
          node -e &quot;
            const fs = require(&#39;fs&#39;);
            const path = &#39;${{ env.PACKAGE_JSON_PATH }}&#39;;
            const pkg = JSON.parse(fs.readFileSync(path, &#39;utf8&#39;));
            pkg.version = &#39;$NEW_VERSION&#39;;
            fs.writeFileSync(path, JSON.stringify(pkg, null, &#39;\t&#39;) + &#39;\n&#39;);
          &quot;
          echo &quot;Updated ${{ env.PACKAGE_JSON_PATH }} to version $NEW_VERSION&quot;
      - name: Commit and push changes
        run: |
          git add &quot;${{ env.PACKAGE_JSON_PATH }}&quot;
          
          if git diff --staged --quiet; then
            echo &quot;No changes to commit.&quot;
          else
            CURRENT_VERSION=&quot;${{ steps.current-version.outputs.current_version }}&quot;
            NEW_VERSION=&quot;${{ steps.new-version.outputs.new_version }}&quot;
            git commit -m &quot;chore: bump version from $CURRENT_VERSION to $NEW_VERSION&quot;
            git push origin master
            echo &quot;Committed and pushed version bump: $CURRENT_VERSION -&gt; $NEW_VERSION&quot;
          fi
</code></pre>
</details>

<details>
<summary>sync-readme-and-update-upm-branch.yaml</summary>

<p>I configure this to also run on <code>push</code> because this ensures my README files and upm-branch contents are always up to date.</p>
<pre><code class="language-yaml"># Used for Unity UPM repositories where the main/master branch has the Unity project root and the actual UPM package directory is somewhere inside Assets/
# This file updates Assets/../README.md based on the latest root README.md
# Then updates a dedicated UPM branch
# Configure env variables based on your needs

name: Sync README and Update UPM Branch

on:
  push:
    branches:
      - master
  workflow_dispatch:

env:
  SUBDIRECTORY_PATH: Assets/Adrenak.BRW
  UPM_BRANCH: upm-latest

jobs:
  sync-readme:
    runs-on: ubuntu-latest
    permissions:
      contents: write
    
    steps:
      - name: Checkout repository
        uses: actions/checkout@v4
        with:
          token: ${{ secrets.GITHUB_TOKEN }}
          fetch-depth: 0

      - name: Configure Git
        run: |
          git config user.name &quot;github-actions[bot]&quot;
          git config user.email &quot;github-actions[bot]@users.noreply.github.com&quot;
      - name: Check if README needs update
        id: check-readme
        run: |
          ROOT_README=&quot;README.md&quot;
          SUB_README=&quot;${{ env.SUBDIRECTORY_PATH }}/README.md&quot;
          
          if [ ! -f &quot;$ROOT_README&quot; ]; then
            echo &quot;Root README.md not found. Exiting.&quot;
            exit 1
          fi
          
          if [ ! -f &quot;$SUB_README&quot; ]; then
            echo &quot;needs_update=true&quot; &gt;&gt; $GITHUB_OUTPUT
            echo &quot;Subdirectory README.md does not exist. Will create it.&quot;
          elif ! cmp -s &quot;$ROOT_README&quot; &quot;$SUB_README&quot;; then
            echo &quot;needs_update=true&quot; &gt;&gt; $GITHUB_OUTPUT
            echo &quot;README.md files differ. Will update subdirectory README.&quot;
          else
            echo &quot;needs_update=false&quot; &gt;&gt; $GITHUB_OUTPUT
            echo &quot;README.md files are identical. No update needed.&quot;
          fi
      - name: Copy README to subdirectory
        if: steps.check-readme.outputs.needs_update == &#39;true&#39;
        run: |
          mkdir -p &quot;${{ env.SUBDIRECTORY_PATH }}&quot;
          cp README.md &quot;${{ env.SUBDIRECTORY_PATH }}/README.md&quot;
          echo &quot;Copied README.md to ${{ env.SUBDIRECTORY_PATH }}/&quot;
      - name: Commit and push changes
        if: steps.check-readme.outputs.needs_update == &#39;true&#39;
        run: |
          git add &quot;${{ env.SUBDIRECTORY_PATH }}/README.md&quot;
          
          if git diff --staged --quiet; then
            echo &quot;No changes to commit.&quot;
          else
            git commit -m &quot;chore: sync README.md to ${{ env.SUBDIRECTORY_PATH }}/&quot;
            git push origin master
            echo &quot;Committed and pushed README.md update.&quot;
          fi
  update-upm-branch:
    needs: sync-readme
    runs-on: ubuntu-latest
    permissions:
      contents: write
    
    steps:
      - name: Checkout master branch
        uses: actions/checkout@v4
        with:
          token: ${{ secrets.GITHUB_TOKEN }}
          fetch-depth: 0
          ref: master

      - name: Configure Git
        run: |
          git config user.name &quot;github-actions[bot]&quot;
          git config user.email &quot;github-actions[bot]@users.noreply.github.com&quot;
      - name: Check if subdirectory exists
        id: check-subdir
        run: |
          if [ ! -d &quot;${{ env.SUBDIRECTORY_PATH }}&quot; ]; then
            echo &quot;Subdirectory ${{ env.SUBDIRECTORY_PATH }} not found. Exiting.&quot;
            exit 1
          fi
          echo &quot;Subdirectory found: ${{ env.SUBDIRECTORY_PATH }}&quot;
      - name: Copy subdirectory to temporary location
        run: |
          # Copy subdirectory contents to a temp location before switching branches
          mkdir -p /tmp/package-contents
          cp -r &quot;${{ env.SUBDIRECTORY_PATH }}&quot;/* /tmp/package-contents/ 2&gt;/dev/null || true
          cp -r &quot;${{ env.SUBDIRECTORY_PATH }}&quot;/.[!.]* /tmp/package-contents/ 2&gt;/dev/null || true
          echo &quot;Copied contents to temporary location&quot;
      - name: Create or checkout upm-latest branch
        run: |
          # Check if branch exists
          if git ls-remote --heads origin ${{ env.UPM_BRANCH }} | grep -q &quot;${{ env.UPM_BRANCH }}&quot;; then
            echo &quot;Branch ${{ env.UPM_BRANCH }} exists. Checking out...&quot;
            git fetch origin ${{ env.UPM_BRANCH }}:${{ env.UPM_BRANCH }}
            git checkout ${{ env.UPM_BRANCH }}
          else
            echo &quot;Branch ${{ env.UPM_BRANCH }} does not exist. Creating...&quot;
            git checkout --orphan ${{ env.UPM_BRANCH }}
            git rm -rf --cached . || true
          fi
      - name: Clear branch contents
        run: |
          # Remove all files except .git
          find . -mindepth 1 -maxdepth 1 ! -name &#39;.git&#39; -exec rm -rf {} +
      - name: Copy subdirectory contents to branch root
        run: |
          # Copy from temporary location to branch root
          cp -r /tmp/package-contents/* .
          echo &quot;Copied contents from temporary location to branch root&quot;
      - name: Commit and push changes
        run: |
          git add -A
          
          if git diff --staged --quiet &amp;&amp; git diff --quiet; then
            echo &quot;No changes to commit.&quot;
          else
            git commit -m &quot;chore: update upm-latest branch with latest package contents&quot;
            git push origin ${{ env.UPM_BRANCH }}
            echo &quot;Committed and pushed to ${{ env.UPM_BRANCH }} branch.&quot;
          fi
</code></pre>
</details></div>
<div id="content-content/posts-md" class="content-section" style="display: none;">
<h1>Posts</h1>
<h2>Tags</h2>
<p><a href="?tag=opensource">opensource (14)</a> ‚Ä¢ <a href="?tag=univoice">univoice (13)</a> ‚Ä¢ <a href="?tag=film">film (2)</a> ‚Ä¢ <a href="?tag=gamedev">gamedev (2)</a> ‚Ä¢ <a href="?tag=life">life (2)</a> ‚Ä¢ <a href="?tag=travel">travel (1)</a> ‚Ä¢ <a href="?tag=unimic">unimic (1)</a></p>
<hr>
<h2><a href="?post=github-workflows-for-upm">Some Github workflows for UPM repositories</a></h2>
<p>Making life a little easier.</p>
<div class="post-entry">
<img src="content/images/oasis-australia.jpg" alt="Oasis reunion and a year with (almost) no social media" class="post-thumbnail" />
<div class="post-content">
<h2><a href="?post=oasis-in-australia">Oasis reunion and a year with (almost) no social media</a></h2>
<p>The great wait is over.</p>
</div>
</div>

<h2><a href="?post=univoice-simple-vad">UniVoice 4.10.0 SimpleVadFilter</a></h2>
<p>Simple Voice Activity Detection to reduce bandwidth usage.</p>
<div class="post-entry">
<img src="content/images/detour/1.png" alt="Making Detour, a short and wholesome supernatural horror game" class="post-thumbnail" />
<div class="post-content">
<h2><a href="?post=making-detour">Making Detour, a short and wholesome supernatural horror game</a></h2>
<p>I made a game!</p>
</div>
</div>

<h2><a href="?post=univoice-wavfilewriter">UniVoice 4.9.0  WavFileWriter and plans for recording features</a></h2>
<p>Write streaming audio to .wav files. More advanced features to come!</p>
<h2><a href="?post=univoice-fishnet-support">UniVoice 4.8.0  FishNet support</a></h2>
<p>UniVoice has early FishNet support, consider it in beta. Thanks to Frantisek Holubec for the contribution!</p>
<h2><a href="?post=univoice-client-tags">UniVoice 4.7.0  Client Tags</a></h2>
<p>Create chat groups within a chatroom easily. E.g. team voice chat in a 5v5 game</p>
<h2><a href="?post=univoice-per-peer-output-filters">UniVoice 4.6.0  Per peer output filters</a></h2>
<p>Each connected peer now has their own filter list. This fixes an Opus decoding bug.</p>
<div class="post-entry">
<img src="content/images/deepdoor.jpg" alt="The missing lore of DEEPDOOR" class="post-thumbnail" />
<div class="post-content">
<h2><a href="?post=deepdoor-lore">The missing lore of DEEPDOOR</a></h2>
<p>This was a pretty short game and left many things unexplained. There was more to it.</p>
</div>
</div>

<h2><a href="?post=unimic-metater-thanks">UniMic 3.3.0  StreamedAudioSource improvements, thanks to Metater@github</a></h2>
<p>Updates to UniMic that makes playback of real-time streaming audio much better.</p>
<h2><a href="?post=univoice-recipe-adding-proximity-audio">UniVoice recipe  Adding proximity audio</a></h2>
<p>People keep asking me about it, it&#39;s achievable and quite simple. Here&#39;s a guide!</p>
<h2><a href="?post=mirror-host-mode-support">UniVoice 4.5.1  Mirror Host mode support</a></h2>
<p>Because sometimes the server is also a client. Read this for co-op or relay server based games.</p>
<h2><a href="?post=morning-thoughts">Morning thoughts of a night owl</a></h2>
<p>After a decade of inconsistent sleeping habits I finally seem to have found something that works for me.</p>
<div class="post-entry">
<img src="content/images/univoice-mirror-basic-tutorial.webp" alt="UniVoice 4.4.0  Drag and drop integration (with YouTube tutorial)" class="post-thumbnail" />
<div class="post-content">
<h2><a href="?post=univoice-drag-and-drop-integration">UniVoice 4.4.0  Drag and drop integration (with YouTube tutorial)</a></h2>
<p>Most UniVoice integration are pretty similar. So just use (or modify) this script.</p>
</div>
</div>

<h2><a href="?post=univoice-easy-push-to-talk">UniVoice 4.3.0  Easy Push To Talk</a></h2>
<p>Push to talk saves bandwidth and gives your users more control. These new features save you time when implementing it.</p>
<h2><a href="?post=univoice-4-upgrade-guide">UniVoice 4.x.x upgrade guide</a></h2>
<p>A lot of things changed and broke between v3 and v4. Here&#39;s what you need to know.</p>
<h2><a href="?post=univoice-rnnoise">UniVoice 4.2.0  RNNoise noise cancellation</a></h2>
<p>Just because your mic captures every little thing doesn&#39;t mean the other person needs to hear it. Filter that noise!</p>
<h2><a href="?post=univoice-mono-repo">UniVoice is now (almost) a mono repo</a></h2>
<p>All those separate repos were really slowing everyone down. A few things still exist in separate repos.</p>
</div>
<div id="content-content/work-md" class="content-section" data-title="Work" data-description="Vatsal Ambastha's work history" data-keywords="vatsal ambastha, adrenak, unity, work, unity3d, game development, virtual reality, ARVR, bangalore" style="display: none;">
<h1>Work</h1>
<p>This is a selection of projects going back to 2012 that I can disclose and consider notable. </p>
<h2>üíº Jobs &amp; Gigs</h2>
<p>Work I&#39;ve done as an employee / consultant / contractor.</p>
<h3>Current</h3>
<p><strong><a href="https://www.managexr.com">ManageXR</a> (since 2021)</strong><br><em>The</em> best solution for managing VR and AR devices at scale. I am employed as a software engineer working on the Unity stack.</p>
<p><strong>Masaryk University (since 2025)</strong><br>Close collaboration consulting with a team of researchers and developers at Masaryk University using UniVoice for their projects.</p>
<details>
<summary>Past Engagements</summary>

<h3>2022</h3>
<p><strong><a href="https://en.wikipedia.org/wiki/Le_Musk">Le Musk</a></strong><br>Film directorial debut of A.R. Rahman, the Oscar, Grammy, Emmy and Golden Globe winning music director.</p>
<p>I worked on making VR playback software for PCVR and Quest headsets. I also made holographic demos for Looking Glass displays that were used at the <a href="https://www.marchedufilm.com/news/le-musk-by-a-r-rahman-a-brave-new-frontier-in-the-cinematic-sensory-vr-experience-to-premiere-at-cannes-xr-this-month/">Cannes Film Festival 2022 screening</a>.
<br><br></p>
<p><strong>eCommerce Metaverse App</strong><br>Developed/refactored parts of a Unity based Metaverse app where users can buy real world items using crytocurrency. Used medusa.js, Mirror Networking, UniVoice, Dissonance and ChainSafe SDK.</p>
<h3>2021</h3>
<p><strong><a href="https://moonfroglabs.com/">Moonfrog Labs</a></strong><br>Helped finish Carrom Gold. Explored opportunities to help speed up and streamline the development process through best practices, reusable software, and infrastructure.
<br><br></p>
<p><strong><a href="https://dopplr.digital/">dopplr.digital</a></strong><br>Social, digital fashion. Worked on code quality &amp; architecture, technical planning along with systems for avatar, clothing, and UI in Unity.</p>
<h3>2020</h3>
<p><strong><a href="https://www.behance.net/gallery/134629563/Quixana-VR">Quixana VR</a></strong><br>Packaging videos like setup files that can be played in a custom video player. Meant for offline video distribution.
<br><br></p>
<p><strong><a href="https://x.com/VatsalAmbastha/status/1326094777159352321">Physiotherapy VR</a></strong><br>A healthcare application to aid in hand-eye coordination for recovering patients.</p>
<h3>2019</h3>
<p><strong><a href="https://scutirewards.com/">Scuti</a></strong><br>Contracted by MindTrust Labs to work on an eCommerce Unity SDK that combines in-game purchases and real world items.
<br><br></p>
<p><strong><a href="https://www.virtue.io/lookback/">LookBack</a></strong><br>A VR therapy application. Uses Google Maps APIs. Has a companion remote app that communicates over the local network with the VR headset. The mobile app beeps a sequence of sounds and the headset connects to it, no need to input the IP or use network discovery.
<br><br></p>
<p><strong><a href="https://yourstory.com/2019/04/ai-startup-bigthinx-ecommerce-fashion">Bigthinx</a></strong><br>Complete development of an app for virtual fashion try-ons in Unity.
<br><br></p>
<p><strong>Digibeings (Co-Founder)</strong><br>AI powered Virtual Beings. Early stage venture, now dormant.</p>
<h3>2018</h3>
<p><strong><a href="https://www.behance.net/gallery/73361295/Encadenor">ENCADENAR: Envisioning Atomic Spaces or My contribution to the Nu-Clear Priesthood</a></strong><br>VR art-game about the Waste Isolation Pilot Project in a fictional future. Envisioned by Mateo Galindo. <a href="https://post45.org/2019/04/the-jewel-of-the-north-mateo-galindos-encadenar-in-space/">Here&#39;s an article</a>. <a href="https://mateogalindo.com/encadenar">Mateo&#39;s website</a>
<br><br></p>
<p><strong><a href="https://www.behance.net/gallery/73361449/Project-Kahaani">Codename Kahaani</a></strong><br>A digital art exhibit inspired from Ian Cheng&#39;s Live Simulations. Made for <a href="https://luisenriquezk.com/">Luis Enrique Zela-Koort</a>
<br><br></p>
<p><strong><a href="https://luisenriquezk.com/intranscendence/">Being in the gaze (Protoconscious)</a></strong><br>VR installation art. Made for Luis Enrique Zela-Koort
<br><br></p>
<p><strong>VR Video Packing</strong><br>R&amp;D project for Fraunhofer Heinrich Hertz Institute.</p>
<p>Prototype for playing packed cubemap and equirectangular projection videos of 6K resolution in Samsung GearVR. The research was about packing high resolution video frames into custom ones with varying resolutions based on area of interest. 
<br><br></p>
<p><strong><a href="https://www.behance.net/gallery/73361793/The-Voice-Stage-Replica-VR">The Voice stage replica</a></strong><br>Level design for a VR singing game.</p>
<h3>2017</h3>
<p><strong><a href="https://www.facebook.com/vatsalAmbastha/videos/1717156575015830">Sciophobia</a></strong><br>VR adaptation of a painting.
<br><br></p>
<p><strong><a href="https://www.behance.net/gallery/73361707/VR-Apocalypse">Post Apocalyptic Level Design</a></strong><br>Level design for a VR game.
<br><br></p>
<p><strong><a href="https://www.behance.net/gallery/73361159/Cyanide-Leak-Sim">Cyanide Leak Sim</a></strong><br>Made a few iPhone and PC sims for training in cyanide leak scenarios. <a href="https://www.hazmatclasses.com/">Client website</a>.</p>
<h3>2016</h3>
<p><strong>The Zero Games</strong><br>Employed as a Software Engineer for the Unity SDK. Developers in-game advertising plugins for game developers. Helped integrate with popular sports and movie IP based games.
<br><br></p>
<p><strong><a href="https://www.behance.net/gallery/42933135/Art-Gallery-Interactive-Unity3D-Tour">Easton Art Gallery 3D</a></strong><br>A mobile and web 3D space for an art gallery.
<br><br></p>
<h3>2013</h3>
<p><strong>Art Outsourcing Partner</strong><br>Provided game art for several mobile game projects in development at Vasco Games B.V. and MobilePlus.</p>
</details>

<h2>üõ†Ô∏è Own Projects</h2>
<p>Things I have built by myself or with a team I&#39;ve put together</p>
<h3>2025</h3>
<p><strong><a href="https://adrenak.itch.io/detour">Detour</a></strong><br>A short (15 minute) game inspired by Fargo and Twin Peaks. It&#39;s a paranormal but wholesome mystery experience.</p>
<h3>2021</h3>
<p><strong><a href="https://www.retroreel.app/">Retro Reel</a></strong><br>A movie streaming app for classic Hollywood fans. ~2000 movies with subtitles in English, Spanish and Portuguese. 200K downloads on Android Play Store.</p>
<p><strong><a href="https://adrenak.itch.io/deepdoor">DEEPDOOR</a></strong><br>A short horror game inspired by the movies Being John Malkovich and The Silence Of the Lambs. Reached Global Top 10 on Itch.io</p>
<details>
<summary>Older Projects</summary>

<h3>2020</h3>
<p><strong><a href="https://www.behance.net/gallery/101101619/XPro-Rally-2-%28In-Development%29">XPro Rally 2</a></strong><br>A rally racing game currently on hold, but I&#39;ll pick it up the first chance I get! <a href="https://www.youtube.com/watch?v=KERgC9t2N94">Here&#39;s a short video</a>.</p>
<h3>2015</h3>
<p><strong><a href="https://medium.com/@tanaygaherwar/video-ads-rise-of-watch-to-win-dbfa8a71c89a">UnSDK</a></strong><br>An analytics platform for recognizing users that monetize highly with video ads. The platform was tested on an in-house game but not released. All that remains now is a blogpost we wrote.
<br>
This was also the end of Firexit Software&#39;s operations, the game studio I founded in 2021 while in university.
<br><br></p>
<p><strong><a href="https://www.indiedb.com/games/speed-street-2">Speed Street 2</a></strong><br>Open world mobile racing game. Never finished but had some demos out including a Google Cardboard VR preview.</p>
<h3>2014</h3>
<p><strong>Speed Street: Escape</strong><br>Infinite runner mode for the popular Speed Street: Tokyo game. Published separately as a browser game on racing3dgames.com (a webgame site no longer operating)
<br><br></p>
<p><strong>Speed Street: Tokyo</strong><br>Android street racing game. 500,000+ downloads. No longer on the Play Store, <a href="https://speed-street.en.uptodown.com/android">here&#39;s</a> an APK mirror website if you want to see some screenshots. <a href="https://www.youtube.com/watch?v=oHJoaNUd4iw&t=24s">Here&#39;s a gameplay video</a>.
<br><br></p>
<p><strong><a href="https://www.youtube.com/watch?v=wvADrEJzD9Y">Blockalypse Now!</a></strong><br>Casual zombie shooting game for Android.</p>
<h3>2013</h3>
<p><strong><a href="https://www.youtube.com/watch?v=EUZAb2-W_EY">XPro Rally Android</a></strong><br>Originally port of the web game that I made thinking &quot;in case this Android thing sticks around&quot;. Ranked on the top free games in about 50 countries. 1 million+ downloads.</p>
<h3>2012</h3>
<p><strong><a href="https://www.youtube.com/watch?v=EUZAb2-W_EY">XPro Rally Web Game</a></strong><br>Rally racing game on the browser. 5+ million plays that I know of across different gaming portals. Based on Unity Web Player which Chrome <a href="https://en.wikipedia.org/wiki/Google_Native_Client">stopped supporting</a> a few years later.</p>
</details>

<h2>‚õìÔ∏è‚Äçüí• Open Source</h2>
<p>Because the best things in life are free.  </p>
<p><strong><a href="https://www.github.com/adrenak/univoice">UniVoice</a></strong><br>A P2P VoIP solution for Unity. Uses my libraries AirPeer for networking and UniMic for audio input.</p>
<p><strong><a href="https://github.com/adrenak/unimic">UniMic</a></strong><br>Enhancements over Unity&#39;s Microphone class.</p>
<p><strong><a href="https://github.com/adrenak/gorky">Gorky</a></strong><br>Markdown to HTML static site generator. This website you&#39;re currently reading uses Gorky.</p>
<p><strong><a href="https://github.com/adrenak/Tork">Tork</a></strong><br>Vehicle physics system for Unity. Offers a WheelCollider replacement with a different friction model. Major updates pending here, not exactly production ready. <a href="https://www.youtube.com/watch&v=gso45Zg_Z_Q">Video</a></p>
<p><strong><a href="https://github.com/adrenak/ugx">UGX</a></strong><br>A UI framework for Unity UGUI. Made for and used in Retro Reel and then later at ManageXR for our user-facing VR application.</p>
<p><strong><a href="https://github.com/adrenak/Trill">Trill</a></strong><br>Transmit and receive data via sound beeps.</p>
<p><strong><a href="https://github.com/adrenak/airpeer">AirPeer</a></strong><br>A WebRTC based networking plugin for Unity. Deprecated, but a useful resource nonetheless.</p>
<p><strong><a href="https://github.com/adrenak/gpuvideoplayer">GPUVideoPlayer</a></strong><br>HEVC decoded video player for Windows systems. Deprecated but still usable if you&#39;re using older software.</p>
</div>

            </div>
        </main>
    </div>

    <script>
        // ============================================================================
        // SITE CONFIGURATION - Loaded from site-config.js
        // ============================================================================
        const SITE_CONFIG =             {
                      "baseUrl": "https://adrenak.github.io",
                      "siteName": "Vatsal Ambastha",
                      "authorName": "Vatsal Ambastha",
                      "defaultDescription": "Personal website and blog of Vatsal Ambastha",
                      "defaultKeywords": "Unity, game development, virtual reality, ManageXR, open source, unity3d, AR, VR",
                      "favicon": "favicon.ico",
                      "appleTouchIcon": "apple-touch-icon.png",
                      "goatCounterEnabled": true,
                      "goatCounterCode": "vatsalambastha",
                      "allowLocal": false,
                      "allowFrame": false,
                      "noOnload": false,
                      "sidebar": {
                                "header": "Vatsal Ambastha",
                                "homeDisplayName": "üè† Home",
                                "postsDisplayName": "‚úçÔ∏è Posts",
                                "footer": [
                                          {
                                                    "text": "2025 ¬© Vatsal Ambastha",
                                                    "target": "https://adrenak.github.io",
                                                    "openInNewTab": true
                                          },
                                          {
                                                    "text": "Get this website template",
                                                    "target": "https://github.com/adrenak/gorky",
                                                    "openInNewTab": true
                                          }
                                ],
                                "sections": {
                                          "": {
                                                    "Work": {
                                                              "target": "?page=work",
                                                              "openInNewTab": false
                                                    }
                                          },
                                          "üîó Links": {
                                                    "Email": {
                                                              "target": "mailto:ambastha.vatsal@gmail.com",
                                                              "openInNewTab": true
                                                    },
                                                    "Github": {
                                                              "target": "https://www.github.com/adrenak",
                                                              "openInNewTab": true
                                                    },
                                                    "LinkedIn": {
                                                              "target": "https://www.linkedin.com/in/vatsalambastha",
                                                              "openInNewTab": true
                                                    }
                                          }
                                }
                      }
            };
        
        // ============================================================================
        // CONSTANTS
        // ============================================================================
        
        const BASE_URL = SITE_CONFIG.baseUrl;
        const SITE_NAME = SITE_CONFIG.siteName;
        const AUTHOR_NAME = SITE_CONFIG.authorName;
        const DEFAULT_PAGE = 'content/home.md';
        const CONTENT_ID_PREFIX = 'content-';
        const TAG_LIST_ID = 'tag-posts-list';
        
        // ============================================================================
        // UTILITY FUNCTIONS
        // ============================================================================
        
        /**
         * Gets a URL parameter value
         * @param {string} name - Parameter name
         * @returns {string|null} Parameter value or null
         */
        function getURLParameter(name) {
            const urlParams = new URLSearchParams(window.location.search);
            return urlParams.get(name);
        }
        
        /**
         * Generates a content section ID from a file path
         * @param {string} filePath - File path (e.g., 'content/home.md')
         * @returns {string} Content ID (e.g., 'content-content-home-md')
         */
        function getContentId(filePath) {
            return CONTENT_ID_PREFIX + filePath.replace(/\./g, '-');
        }
        
        /**
         * Hides all content sections
         */
        function hideAllContentSections() {
            document.querySelectorAll('.content-section').forEach(section => {
                section.style.display = 'none';
            });
        }
        
        /**
         * Removes active class from all navigation links
         */
        function clearActiveNavLinks() {
            document.querySelectorAll('.nav-link').forEach(nav => {
                nav.classList.remove('active');
            });
        }
        
        /**
         * Highlights syntax in code blocks using Prism.js
         * @param {Element} container - Container element to search for code blocks
         */
        function highlightSyntax(container) {
            if (!window.Prism) return;
            
            const codeBlocks = container.querySelectorAll('pre code[class*="language-"]');
            codeBlocks.forEach(block => {
                Prism.highlightElement(block);
            });
        }
        
        /**
         * Hides the tag posts list container if it exists
         */
        function hideTagListContainer() {
            const tagListContainer = document.getElementById(TAG_LIST_ID);
            if (tagListContainer) {
                tagListContainer.style.display = 'none';
            }
        }
        
        /**
         * Parses a formatted date string to a Date object
         * @param {string} dateStr - Date string in format "25 Sep 2025"
         * @returns {Date} Parsed date object
         */
        function parseFormattedDate(dateStr) {
            const MONTHS = {
                'Jan': 0, 'Feb': 1, 'Mar': 2, 'Apr': 3, 'May': 4, 'Jun': 5,
                'Jul': 6, 'Aug': 7, 'Sep': 8, 'Oct': 9, 'Nov': 10, 'Dec': 11
            };
            
            const parts = dateStr.split(' ');
            if (parts.length !== 3) {
                return new Date(0);
            }
            
            const day = parseInt(parts[0], 10);
            const month = MONTHS[parts[1]];
            const year = parseInt(parts[2], 10);
            
            if (isNaN(day) || month === undefined || isNaN(year)) {
                return new Date(0);
            }
            
            return new Date(year, month, day);
        }
        
        /**
         * Sets the active navigation link based on current page
         * @param {string} expectedURL - Expected URL to match (e.g., '?page=home')
         */
        function setActiveNavLink(expectedURL) {
            // Check data-url attributes (for internal navigation)
            document.querySelectorAll('.nav-link[data-url]').forEach(link => {
                const targetURL = link.getAttribute('data-url');
                if (targetURL === expectedURL) {
                    link.classList.add('active');
                }
            });
            
            // Also check href attributes (for links that open in new tab)
            document.querySelectorAll('.nav-link').forEach(link => {
                const href = link.getAttribute('href');
                if (href === expectedURL) {
                    link.classList.add('active');
                }
            });
        }
        
        /**
         * Creates a clickable tag link element
         * @param {string} tag - Tag name
         * @returns {HTMLAnchorElement} Tag link element
         */
        function createTagLink(tag) {
            const tagLink = document.createElement('a');
            tagLink.href = `?tag=${encodeURIComponent(tag)}`;
            tagLink.textContent = tag;
            tagLink.className = 'tag-link';
            
            tagLink.addEventListener('click', function(e) {
                e.preventDefault();
                showPostsByTag(tag);
                window.history.pushState({}, '', `?tag=${encodeURIComponent(tag)}`);
                updateCanonicalURL();
            });
            
            return tagLink;
        }
        
        /**
         * Updates the canonical URL based on current page
         */
        function updateCanonicalURL() {
            const tagParam = getURLParameter('tag');
            const pageParam = getURLParameter('page');
            const postSlug = getURLParameter('post');
            
            let canonicalURL = BASE_URL;
            
            if (postSlug) {
                canonicalURL += `?post=${postSlug}`;
            } else if (tagParam) {
                canonicalURL += `?tag=${encodeURIComponent(tagParam)}`;
            } else if (pageParam === 'posts') {
                canonicalURL += '?page=posts';
            } else {
                canonicalURL += '?page=home';
            }
            
            let canonicalLink = document.querySelector('link[rel="canonical"]');
            if (!canonicalLink) {
                canonicalLink = document.createElement('link');
                canonicalLink.setAttribute('rel', 'canonical');
                document.head.appendChild(canonicalLink);
            }
            canonicalLink.setAttribute('href', canonicalURL);
        }
        
        /**
         * Helper function to get or create a meta tag
         */
        function getOrCreateMetaTag(attribute, value, property = false) {
            const selector = property ? `meta[property="${attribute}"]` : `meta[name="${attribute}"]`;
            let meta = document.querySelector(selector);
            if (!meta) {
                meta = document.createElement('meta');
                if (property) {
                    meta.setAttribute('property', attribute);
                } else {
                    meta.setAttribute('name', attribute);
                }
                document.head.appendChild(meta);
            }
            meta.setAttribute('content', value);
        }
        
        /**
         * Removes a meta tag if it exists
         */
        function removeMetaTag(attribute, property = false) {
            const selector = property ? `meta[property="${attribute}"]` : `meta[name="${attribute}"]`;
            const meta = document.querySelector(selector);
            if (meta) {
                meta.remove();
            }
        }
        
        /**
         * Converts a relative URL to absolute URL
         */
        function getAbsoluteUrl(relativeUrl) {
            if (!relativeUrl) return null;
            if (relativeUrl.startsWith('http://') || relativeUrl.startsWith('https://')) {
                return relativeUrl;
            }
            // Remove leading slash if present, BASE_URL should handle it
            const cleanUrl = relativeUrl.startsWith('/') ? relativeUrl.slice(1) : relativeUrl;
            return `${BASE_URL}/${cleanUrl}`;
        }
        
        /**
         * Updates meta tags (title, description, keywords, Open Graph, Twitter Cards) and structured data based on current content
         */
        function updateMetaTags() {
            const tagParam = getURLParameter('tag');
            const postSlug = getURLParameter('post');
            const pageParam = getURLParameter('page');
            
            let title = SITE_CONFIG.siteName;
            let description = SITE_CONFIG.defaultDescription;
            let keywords = SITE_CONFIG.defaultKeywords;
            let image = null;
            let url = BASE_URL;
            let datePublished = null;
            let tags = null;
            let author = null;
            let isPost = false;
            
            // Get meta tags from current visible content section
            const visibleSection = document.querySelector('.content-section[style*="block"]') || 
                                  document.querySelector('.content-section:not([style*="none"])');
            
            if (visibleSection) {
                const sectionTitle = visibleSection.getAttribute('data-title');
                const sectionDescription = visibleSection.getAttribute('data-description');
                const sectionKeywords = visibleSection.getAttribute('data-keywords');
                const sectionThumbnail = visibleSection.getAttribute('data-thumbnail');
                const sectionDate = visibleSection.getAttribute('data-date');
                const sectionTags = visibleSection.getAttribute('data-tags');
                const sectionSlug = visibleSection.getAttribute('data-slug');
                const sectionAuthor = visibleSection.getAttribute('data-author');
                
                if (sectionTitle) {
                    title = sectionTitle;
                }
                
                if (sectionDescription) {
                    description = sectionDescription;
                }
                
                if (sectionKeywords) {
                    keywords = sectionKeywords;
                } else if (tagParam) {
                    keywords = tagParam;
                }
                
                if (sectionThumbnail) {
                    image = getAbsoluteUrl(sectionThumbnail);
                }
                
                if (sectionDate) {
                    datePublished = sectionDate;
                }
                
                if (sectionTags) {
                    tags = sectionTags.split(',').map(t => t.trim());
                }
                
                if (sectionAuthor) {
                    author = sectionAuthor;
                }
                
                if (sectionSlug) {
                    url = `${BASE_URL}?post=${sectionSlug}`;
                    isPost = true;
                }
            } else if (tagParam) {
                // Tag filtering page
                title = `Posts tagged ${tagParam} - ${SITE_NAME}`;
                keywords = tagParam;
                url = `${BASE_URL}?tag=${encodeURIComponent(tagParam)}`;
            } else if (postSlug) {
                // Fallback: try to find post by slug
                const postSection = document.querySelector(`.content-section[data-slug="${postSlug}"]`);
                if (postSection) {
                    const postTitle = postSection.getAttribute('data-title');
                    const postDescription = postSection.getAttribute('data-description');
                    const postKeywords = postSection.getAttribute('data-keywords');
                    const postThumbnail = postSection.getAttribute('data-thumbnail');
                    const postDate = postSection.getAttribute('data-date');
                    const postTags = postSection.getAttribute('data-tags');
                    const postAuthor = postSection.getAttribute('data-author');
                    
                    if (postTitle) title = postTitle;
                    if (postDescription) description = postDescription;
                    if (postKeywords) keywords = postKeywords;
                    if (postThumbnail) image = getAbsoluteUrl(postThumbnail);
                    if (postDate) datePublished = postDate;
                    if (postTags) tags = postTags.split(',').map(t => t.trim());
                    if (postAuthor) author = postAuthor;
                    
                    url = `${BASE_URL}?post=${postSlug}`;
                    isPost = true;
                }
            } else if (pageParam) {
                url = `${BASE_URL}?page=${pageParam}`;
            } else {
                url = `${BASE_URL}?page=home`;
            }
            
            // Update title
            document.title = title;
            
            // Update basic meta tags
            getOrCreateMetaTag('description', description);
            getOrCreateMetaTag('keywords', keywords);
            
            // Update Open Graph tags
            getOrCreateMetaTag('og:title', title, true);
            getOrCreateMetaTag('og:description', description, true);
            getOrCreateMetaTag('og:url', url, true);
            getOrCreateMetaTag('og:type', isPost ? 'article' : 'website', true);
            getOrCreateMetaTag('og:site_name', SITE_NAME, true);
            if (image) {
                getOrCreateMetaTag('og:image', image, true);
            } else {
                removeMetaTag('og:image', true);
            }
            
            // Update Twitter Card tags
            getOrCreateMetaTag('twitter:card', image ? 'summary_large_image' : 'summary');
            getOrCreateMetaTag('twitter:title', title);
            getOrCreateMetaTag('twitter:description', description);
            if (image) {
                getOrCreateMetaTag('twitter:image', image);
            } else {
                removeMetaTag('twitter:image');
            }
            
            // Update structured data (JSON-LD)
            updateStructuredData(title, description, image, url, datePublished, tags, author, isPost);
        }
        
        /**
         * Converts formatted date (e.g., "9 Dec 2025") to ISO 8601 format (e.g., "2025-12-09")
         */
        function convertDateToISO(dateStr) {
            if (!dateStr) return null;
            
            const MONTHS = {
                'Jan': '01', 'Feb': '02', 'Mar': '03', 'Apr': '04', 'May': '05', 'Jun': '06',
                'Jul': '07', 'Aug': '08', 'Sep': '09', 'Oct': '10', 'Nov': '11', 'Dec': '12'
            };
            
            const parts = dateStr.split(' ');
            if (parts.length !== 3) return null;
            
            const day = parts[0].padStart(2, '0');
            const month = MONTHS[parts[1]];
            const year = parts[2];
            
            if (!month) return null;
            
            return `${year}-${month}-${day}`;
        }
        
        /**
         * Updates JSON-LD structured data for SEO
         */
        function updateStructuredData(title, description, image, url, datePublished, tags, author, isPost) {
            // Remove existing structured data
            const existingScript = document.querySelector('script[type="application/ld+json"]');
            if (existingScript) {
                existingScript.remove();
            }
            
            if (isPost && datePublished) {
                // Convert date to ISO format for schema.org
                const isoDate = convertDateToISO(datePublished);
                
                // Article schema for blog posts
                const articleSchema = {
                    '@context': 'https://schema.org',
                    '@type': 'BlogPosting',
                    'headline': title,
                    'description': description,
                    'url': url
                };
                
                if (isoDate) {
                    articleSchema.datePublished = isoDate;
                }
                
                if (image) {
                    articleSchema.image = image;
                }
                
                if (tags && tags.length > 0) {
                    articleSchema.keywords = tags.join(', ');
                }
                
                // Add author - use frontmatter author if available, otherwise fallback to AUTHOR_NAME
                const authorName = author || AUTHOR_NAME;
                if (authorName) {
                    articleSchema.author = {
                        '@type': 'Person',
                        'name': authorName
                    };
                }
                
                const script = document.createElement('script');
                script.type = 'application/ld+json';
                script.textContent = JSON.stringify(articleSchema);
                document.head.appendChild(script);
            } else {
                // WebPage schema for other pages
                const webpageSchema = {
                    '@context': 'https://schema.org',
                    '@type': 'WebPage',
                    'name': title,
                    'description': description,
                    'url': url
                };
                
                if (image) {
                    webpageSchema.image = image;
                }
                
                const script = document.createElement('script');
                script.type = 'application/ld+json';
                script.textContent = JSON.stringify(webpageSchema);
                document.head.appendChild(script);
            }
        }
        
        /**
         * Shows post metadata (title, date, tags) for a content section
         * @param {Element} contentSection - Content section element
         */
        function showPostMetadata(contentSection) {
            const date = contentSection.getAttribute('data-date');
            const tags = contentSection.getAttribute('data-tags');
            const title = contentSection.getAttribute('data-title');
            
            if (!title && !date && !tags) return;
            
            let metadataContainer = contentSection.querySelector('.post-metadata');
            if (!metadataContainer) {
                metadataContainer = document.createElement('div');
                metadataContainer.className = 'post-metadata';
                contentSection.insertBefore(metadataContainer, contentSection.firstChild);
            }
            
            metadataContainer.innerHTML = '';
            
            if (title) {
                const titleElement = document.createElement('h1');
                titleElement.className = 'post-title';
                titleElement.textContent = title;
                metadataContainer.appendChild(titleElement);
            }
            
            if (date) {
                const dateElement = document.createElement('div');
                dateElement.className = 'post-date';
                dateElement.textContent = date;
                metadataContainer.appendChild(dateElement);
            }
            
            if (tags) {
                const tagsElement = document.createElement('div');
                tagsElement.className = 'post-tags';
                
                const tagText = document.createTextNode('Tagged: ');
                tagsElement.appendChild(tagText);
                
                const tagList = tags.split(',').map(t => t.trim());
                tagList.forEach((tag, index) => {
                    const tagLink = createTagLink(tag);
                    tagsElement.appendChild(tagLink);
                    
                    if (index < tagList.length - 1) {
                        const comma = document.createTextNode(', ');
                        tagsElement.appendChild(comma);
                    }
                });
                
                metadataContainer.appendChild(tagsElement);
            }
        }
        
        /**
         * Shows content section by post slug
         * @param {string} slug - Post slug
         * @returns {boolean} True if content was found and shown
         */
        function showContentBySlug(slug) {
            if (!slug) return false;
            
            hideTagListContainer();
            
            const contentSection = document.querySelector(`.content-section[data-slug="${slug}"]`);
            if (!contentSection) return false;
            
            hideAllContentSections();
            contentSection.style.display = 'block';
            showPostMetadata(contentSection);
            highlightSyntax(contentSection);
            clearActiveNavLinks();
            updateMetaTags();
            
            return true;
        }
        
        /**
         * Shows content section by file path
         * @param {string} filePath - File path (e.g., 'content/home.md')
         * @returns {boolean} True if content was found and shown
         */
        function showContentByFile(filePath) {
            hideTagListContainer();
            
            const contentId = getContentId(filePath);
            const contentSection = document.getElementById(contentId);
            
            if (!contentSection) return false;
            
            hideAllContentSections();
            contentSection.style.display = 'block';
            highlightSyntax(contentSection);
            clearActiveNavLinks();
            updateMetaTags();
            
            const currentPage = getURLParameter('page');
            if (currentPage) {
                setActiveNavLink(`?page=${currentPage}`);
            }
            
            return true;
        }
        
        /**
         * Shows posts filtered by tag
         * @param {string} tag - Tag to filter by
         * @returns {boolean} True if posts were found and shown
         */
        function showPostsByTag(tag) {
            if (!tag) return false;
            
            // Hide all content sections except tag list container
            document.querySelectorAll('.content-section').forEach(section => {
                if (section.id !== TAG_LIST_ID) {
                    section.style.display = 'none';
                }
            });
            
            // Find all posts with matching tag
            const allPosts = document.querySelectorAll('.content-section[data-tags]');
            const matchingPosts = [];
            
            allPosts.forEach(post => {
                const tags = post.getAttribute('data-tags');
                if (!tags) return;
                
                const tagList = tags.split(',').map(t => t.trim().toLowerCase());
                if (tagList.includes(tag.toLowerCase())) {
                    const slug = post.getAttribute('data-slug');
                    const title = post.getAttribute('data-title');
                    const date = post.getAttribute('data-date');
                    const description = post.getAttribute('data-description');
                    const thumbnail = post.getAttribute('data-thumbnail');
                    
                    if (slug && title) {
                        matchingPosts.push({ slug, title, date, description, thumbnail });
                    }
                }
            });
            
            if (matchingPosts.length === 0) return false;
            
            // Get or create tag list container
            let tagListContainer = document.getElementById(TAG_LIST_ID);
            if (!tagListContainer) {
                tagListContainer = document.createElement('div');
                tagListContainer.id = TAG_LIST_ID;
                tagListContainer.className = 'content-section';
                document.getElementById('markdown-content').appendChild(tagListContainer);
            }
            
            tagListContainer.style.display = 'block';
            tagListContainer.innerHTML = '';
            
            // Add header
            const header = document.createElement('h1');
            header.textContent = `Posts tagged ${tag}`;
            tagListContainer.appendChild(header);
            
            // Sort posts by date (newest first)
            matchingPosts.sort((a, b) => {
                if (!a.date || !b.date) return 0;
                return parseFormattedDate(b.date) - parseFormattedDate(a.date);
            });
            
            // Add post entries (matching posts.md format)
            matchingPosts.forEach(({ slug, title, description, thumbnail }) => {
                // Create post entry container
                const postEntry = document.createElement('div');
                postEntry.className = 'post-entry';
                
                // Add thumbnail if available
                if (thumbnail) {
                    const img = document.createElement('img');
                    img.src = thumbnail;
                    img.alt = title;
                    img.className = 'post-thumbnail';
                    postEntry.appendChild(img);
                }
                
                // Create content container
                const postContent = document.createElement('div');
                postContent.className = 'post-content';
                
                // Add title
                const titleHeading = document.createElement('h2');
                const titleLink = document.createElement('a');
                titleLink.href = `?post=${slug}`;
                titleLink.textContent = title;
                titleLink.className = 'post-link';
                
                titleLink.addEventListener('click', function(e) {
                    e.preventDefault();
                    showContentBySlug(slug);
                    window.history.pushState({}, '', `?post=${slug}`);
                    updateCanonicalURL();
                    updateMetaTags();
                });
                
                titleHeading.appendChild(titleLink);
                postContent.appendChild(titleHeading);
                
                // Add description if available
                if (description) {
                    const descriptionPara = document.createElement('p');
                    descriptionPara.textContent = description;
                    postContent.appendChild(descriptionPara);
                }
                
                postEntry.appendChild(postContent);
                tagListContainer.appendChild(postEntry);
            });
            
            clearActiveNavLinks();
            updateMetaTags();
            return true;
        }
        
        /**
         * Handles URL changes and updates content accordingly
         */
        function handleURLChange() {
            const tagParam = getURLParameter('tag');
            const pageParam = getURLParameter('page');
            const postSlug = getURLParameter('post');
            
            let contentShown = false;
            
            if (tagParam && showPostsByTag(tagParam)) {
                contentShown = true;
            } else if (postSlug && showContentBySlug(postSlug)) {
                contentShown = true;
            } else if (pageParam) {
                const targetFile = `content/${pageParam}.md`;
                contentShown = showContentByFile(targetFile);
            }
            
            if (!contentShown) {
                // Show default page (home) and set Home nav link as active
                showContentByFile(DEFAULT_PAGE);
                clearActiveNavLinks();
                setActiveNavLink('?page=home');
                updateMetaTags();
            }
            
            updateCanonicalURL();
            
            // Track pageview with GoatCounter for client-side routing
            if (SITE_CONFIG.goatCounterEnabled && typeof goatcounter !== 'undefined') {
                goatcounter.count({
                    path: location.pathname + location.search
                });
            }
        }
        
        // ============================================================================
        // INITIALIZATION
        // ============================================================================
        
        // Content switching functionality
        document.addEventListener('DOMContentLoaded', function() {
            // Initialize default meta tags from SITE_CONFIG
            document.getElementById('meta-description').setAttribute('content', SITE_CONFIG.defaultDescription);
            document.getElementById('meta-keywords').setAttribute('content', SITE_CONFIG.defaultKeywords);
            document.getElementById('canonical-link').setAttribute('href', `${SITE_CONFIG.baseUrl}?page=home`);
            document.getElementById('page-title').textContent = SITE_CONFIG.siteName;
            
            // Set favicon if configured
            if (SITE_CONFIG.favicon) {
                const faviconLink = document.getElementById('favicon-link');
                if (faviconLink) {
                    faviconLink.setAttribute('href', SITE_CONFIG.favicon);
                }
            }
            if (SITE_CONFIG.appleTouchIcon) {
                const appleIconLink = document.getElementById('apple-touch-icon-link');
                if (appleIconLink) {
                    appleIconLink.setAttribute('href', SITE_CONFIG.appleTouchIcon);
                }
            }
            
            // Set up nav link click handlers
            // Handle navigation links with data-url (URL parameters)
            const navLinksWithURL = document.querySelectorAll('.nav-link[data-url]');
            navLinksWithURL.forEach(link => {
                link.addEventListener('click', function(e) {
                    e.preventDefault();
                    
                    const targetURL = this.getAttribute('data-url');
                    if (targetURL) {
                        window.history.pushState({}, '', targetURL);
                        handleURLChange();
                    }
                });
            });
            
            // Handle browser back/forward navigation
            window.addEventListener('popstate', function(event) {
                handleURLChange();
            });
            
            // Initial load - handle URL parameters
            handleURLChange();
            
            // Highlight syntax in initially visible content
            if (window.Prism) {
                Prism.highlightAll();
            }
            
            // Hamburger menu toggle functionality
            const hamburgerMenu = document.getElementById('hamburger-menu');
            const sidebar = document.getElementById('sidebar');
            const overlay = document.getElementById('sidebar-overlay');
            
            function toggleSidebar() {
                sidebar.classList.toggle('active');
                overlay.classList.toggle('active');
                hamburgerMenu.classList.toggle('active');
            }
            
            function closeSidebar() {
                sidebar.classList.remove('active');
                overlay.classList.remove('active');
                hamburgerMenu.classList.remove('active');
            }
            
            if (hamburgerMenu) {
                hamburgerMenu.addEventListener('click', toggleSidebar);
            }
            
            if (overlay) {
                overlay.addEventListener('click', closeSidebar);
            }
            
            // Close sidebar when clicking on a nav link (mobile)
            const mobileNavLinks = document.querySelectorAll('.nav-link');
            mobileNavLinks.forEach(link => {
                link.addEventListener('click', function() {
                    // Check if we're in mobile/portrait mode
                    if (window.matchMedia('(max-aspect-ratio: 1/1)').matches) {
                        closeSidebar();
                    }
                });
            });

            // ============================================================================
            // GOATCOUNTER ANALYTICS
            // ============================================================================
            
            if (SITE_CONFIG.goatCounterEnabled && SITE_CONFIG.goatCounterCode) {
                const goatCounterScript = document.createElement('script');
                goatCounterScript.async = true;
                goatCounterScript.setAttribute('data-goatcounter', `https://${SITE_CONFIG.goatCounterCode}.goatcounter.com/count`);
                goatCounterScript.src = '//gc.zgo.at/count.js';
                
                // Add optional data attributes
                if (SITE_CONFIG.allowLocal) {
                    goatCounterScript.setAttribute('data-goatcounter-allow-local', 'true');
                }
                if (SITE_CONFIG.allowFrame) {
                    goatCounterScript.setAttribute('data-goatcounter-allow-frame', 'true');
                }
                if (SITE_CONFIG.noOnload) {
                    goatCounterScript.setAttribute('data-goatcounter-no-onload', 'true');
                }
                
                document.body.appendChild(goatCounterScript);
            }
        });
    </script>
</body>
</html>

